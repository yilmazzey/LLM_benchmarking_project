{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "913e3e5877f744689b49772c5763c5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd55fa145da2467298f8bc08e15c641a",
              "IPY_MODEL_6b2be866b8614ff1997abc2862023f7c",
              "IPY_MODEL_9a4179178ba7467ea4a7ac0a614b1352"
            ],
            "layout": "IPY_MODEL_57edb51c56844566aa51f2a5af92388f"
          }
        },
        "bd55fa145da2467298f8bc08e15c641a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_122ae11dbf0049c99836845294b0d001",
            "placeholder": "​",
            "style": "IPY_MODEL_036bd4d1517642299752eeb9e75093eb",
            "value": "model.safetensors: 100%"
          }
        },
        "6b2be866b8614ff1997abc2862023f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8df7f6e229f04b39829c0fb1600f505a",
            "max": 2354805470,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b33625d5f44e438c932056f5219d1b38",
            "value": 2354805470
          }
        },
        "9a4179178ba7467ea4a7ac0a614b1352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba5b796a65a4d44bd286532ec128fec",
            "placeholder": "​",
            "style": "IPY_MODEL_d75d70be262541829c42f50f9a8edc08",
            "value": " 2.35G/2.35G [02:07&lt;00:00, 12.1MB/s]"
          }
        },
        "57edb51c56844566aa51f2a5af92388f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122ae11dbf0049c99836845294b0d001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "036bd4d1517642299752eeb9e75093eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8df7f6e229f04b39829c0fb1600f505a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b33625d5f44e438c932056f5219d1b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ba5b796a65a4d44bd286532ec128fec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75d70be262541829c42f50f9a8edc08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "859ab372373a4a368879e4ad77cc7dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e7e720dc0064b7a87de40f9855fcfa1",
              "IPY_MODEL_5234d9563f7f4e29b0674cbdc35170d9",
              "IPY_MODEL_3ad37906a18248c695ee283fc695ef6c"
            ],
            "layout": "IPY_MODEL_9a49d220fb084816863909dee65d8723"
          }
        },
        "6e7e720dc0064b7a87de40f9855fcfa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dcfbd898d9d4cb9aed87aa9de3afe60",
            "placeholder": "​",
            "style": "IPY_MODEL_5b02807811044b159e9086ff9702c4e1",
            "value": "generation_config.json: 100%"
          }
        },
        "5234d9563f7f4e29b0674cbdc35170d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a608630cc1d7452aab8aa98d7b231d0a",
            "max": 234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35a2e5e7063d4d0299347795c2c5f3ff",
            "value": 234
          }
        },
        "3ad37906a18248c695ee283fc695ef6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc700c9d24bb41ccb257649d4a4d51bd",
            "placeholder": "​",
            "style": "IPY_MODEL_b5d0da23a15e4471b0485d111d8e52a2",
            "value": " 234/234 [00:00&lt;00:00, 18.9kB/s]"
          }
        },
        "9a49d220fb084816863909dee65d8723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dcfbd898d9d4cb9aed87aa9de3afe60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b02807811044b159e9086ff9702c4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a608630cc1d7452aab8aa98d7b231d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a2e5e7063d4d0299347795c2c5f3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc700c9d24bb41ccb257649d4a4d51bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d0da23a15e4471b0485d111d8e52a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NkK6XX5WvVN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26b4f6c5-41dd-4345-a774-55a1dd9ad833",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.4.7-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting trl\n",
            "  Downloading trl-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting unsloth_zoo>=2025.4.4 (from unsloth)\n",
            "  Downloading unsloth_zoo-2025.4.4-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (24.2)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.9.19-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.0.2)\n",
            "Collecting trl\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting protobuf<4.0.0 (from unsloth)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.30.2)\n",
            "Collecting hf_transfer (from unsloth)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.33.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.4.4->unsloth)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.4.4->unsloth) (11.2.1)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.4.4->unsloth)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting torch>=2.4.0 (from unsloth)\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from unsloth)\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Collecting hf-xet>=0.1.4 (from huggingface_hub[hf_xet]>=0.30.0->unsloth_zoo>=2025.4.4->unsloth)\n",
            "  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
            "Downloading unsloth-2025.4.7-py3-none-any.whl (218 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.5/218.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.4.4-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (31.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m128.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.19-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, xxhash, triton, sympy, shtab, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, hf-xet, hf_transfer, fsspec, dill, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, tyro, nvidia-cusolver-cu12, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 hf-xet-1.1.0 hf_transfer-0.1.9 msgspec-0.19.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 protobuf-3.20.3 shtab-1.7.2 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 triton-3.3.0 trl-0.15.2 tyro-0.9.19 unsloth-2025.4.7 unsloth_zoo-2025.4.4 xformers-0.0.30 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ee8f6f205be04faa8d505ebb3e205247"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install unsloth transformers datasets accelerate trl peft bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerekli kütüphaneler (Unsloth en üstte olmalı!)\n",
        "import unsloth\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import json\n",
        "import gc\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Model ve tokenizer'ı Unsloth üzerinden yüklüyoruz\n",
        "model_path = \"/content/drive/Shareddrives/Senior Design Project/fine_tuned_model_outputs/llama3.2-3b/llama3.2_3B_3epoch_5batch\"\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_path,\n",
        "    max_seq_length=16000,\n",
        "    dtype=torch.float16,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# JSON dosyasını yüklüyoruz\n",
        "with open(\"/content/drive/Shareddrives/Senior Design Project/ShareGPT dataset Fine Tune kodu  test dataseti/second_200_papers_test.json\", \"r\", encoding=\"utf-8\") as file:\n",
        "    articles = json.load(file)\n",
        "\n",
        "# System prompt\n",
        "system_instruction = (\n",
        "    \"You are an expert academic writer specializing in generating high-quality abstracts for scholarly publications.\\n\\n\"\n",
        "    \"Your task is to produce a concise abstract (150-250 words) based on a research paper's title and content. Please ensure the abstract:\\n\"\n",
        "    \"- Clearly states the research problem or question,\\n\"\n",
        "    \"- Summarizes the methodology or approach,\\n\"\n",
        "    \"- Highlights the key findings,\\n\"\n",
        "    \"- Explains the significance or implications of the results.\\n\\n\"\n",
        "    \"Use formal, objective language appropriate for academic journals. Avoid unnecessary jargon and maintain clarity for a broad scholarly audience.\"\n",
        ")\n",
        "\n",
        "# Abstract üretim fonksiyonu\n",
        "def generate_abstract_full_text(article):\n",
        "    title = article[\"title\"]\n",
        "    content = article[\"content\"]\n",
        "\n",
        "    user_prompt = (\n",
        "        \"Generate an academic abstract based on the following paper:\\n\\n\"\n",
        "        f\"Title: {title}\\n\\n\"\n",
        "        f\"Content: {content}\\n\\n\"\n",
        "        \"Please ensure the abstract:\\n\"\n",
        "        \"- Is concise (150-250 words),\\n\"\n",
        "        \"- Clearly states the research problem,\\n\"\n",
        "        \"- Summarizes the methodology,\\n\"\n",
        "        \"- Highlights the key findings,\\n\"\n",
        "        \"- Explains the significance or implications,\\n\"\n",
        "        \"- Uses formal academic language suitable for a scholarly journal,\\n\"\n",
        "        \"- Avoids unnecessary jargon while maintaining clarity.\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_instruction},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    # Prompt formatlama (LLaMA 3 için uygun şekilde)\n",
        "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
        "        full_prompt = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "    else:\n",
        "        full_prompt = f\"<s>[INST] {system_instruction}\\n\\n{user_prompt} [/INST]\"\n",
        "\n",
        "    # Tokenize edip modele ver\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Generate\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=300,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        repetition_penalty=1.2,\n",
        "    )\n",
        "\n",
        "    # Decode et ve prompt kısmını temizle\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    if \"[/INST]\" in response:\n",
        "        response = response.split(\"[/INST]\")[-1].strip()\n",
        "    else:\n",
        "        response = response.replace(full_prompt, \"\").strip()\n",
        "\n",
        "    return response\n",
        "\n",
        "# Bellek temizleme\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# Tüm makaleleri işle\n",
        "results = []\n",
        "processing_times = []\n",
        "start_time_total = time.time()\n",
        "\n",
        "for i, article in enumerate(articles):\n",
        "    start_time = time.time()\n",
        "    print(f\"Processing article {i + 1}/{len(articles)}: {article['title']}\")\n",
        "\n",
        "    try:\n",
        "        abstract = generate_abstract_full_text(article)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating abstract: {e}\")\n",
        "        abstract = \"Error generating abstract.\"\n",
        "\n",
        "    results.append({\n",
        "        \"title\": article[\"title\"],\n",
        "        \"abstract\": abstract\n",
        "    })\n",
        "\n",
        "    # Süre hesaplamaları\n",
        "    elapsed = time.time() - start_time\n",
        "    processing_times.append(elapsed)\n",
        "    avg_time = sum(processing_times) / len(processing_times)\n",
        "    remaining = len(articles) - (i + 1)\n",
        "    eta = datetime.now() + timedelta(seconds=avg_time * remaining)\n",
        "\n",
        "    print(f\"Done in {elapsed:.2f}s | Avg: {avg_time:.2f}s | Remaining: {remaining} | ETA: {eta.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if (i + 1) % 5 == 0:\n",
        "        clear_memory()\n",
        "\n",
        "# Toplam süre\n",
        "total_time = time.time() - start_time_total\n",
        "print(f\"All done in {total_time / 60:.2f} minutes.\")\n",
        "\n",
        "# Sonuçları kaydet\n",
        "with open(\"Llama3.2_3B_3-5_abstracts_second_test.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "clear_memory()\n",
        "print(\"Abstract generation completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "913e3e5877f744689b49772c5763c5db",
            "bd55fa145da2467298f8bc08e15c641a",
            "6b2be866b8614ff1997abc2862023f7c",
            "9a4179178ba7467ea4a7ac0a614b1352",
            "57edb51c56844566aa51f2a5af92388f",
            "122ae11dbf0049c99836845294b0d001",
            "036bd4d1517642299752eeb9e75093eb",
            "8df7f6e229f04b39829c0fb1600f505a",
            "b33625d5f44e438c932056f5219d1b38",
            "8ba5b796a65a4d44bd286532ec128fec",
            "d75d70be262541829c42f50f9a8edc08",
            "859ab372373a4a368879e4ad77cc7dbc",
            "6e7e720dc0064b7a87de40f9855fcfa1",
            "5234d9563f7f4e29b0674cbdc35170d9",
            "3ad37906a18248c695ee283fc695ef6c",
            "9a49d220fb084816863909dee65d8723",
            "7dcfbd898d9d4cb9aed87aa9de3afe60",
            "5b02807811044b159e9086ff9702c4e1",
            "a608630cc1d7452aab8aa98d7b231d0a",
            "35a2e5e7063d4d0299347795c2c5f3ff",
            "dc700c9d24bb41ccb257649d4a4d51bd",
            "b5d0da23a15e4471b0485d111d8e52a2"
          ]
        },
        "id": "GPRYXe5_nh7E",
        "outputId": "2ec3f46e-fe9e-4db1-b801-70e9a16b4a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "913e3e5877f744689b49772c5763c5db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "859ab372373a4a368879e4ad77cc7dbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.4.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing article 1/200: discourse-aware_unsupervised_summarization_for_long_scientific_documents\n",
            "Done in 18.44s | Avg: 18.44s | Remaining: 199 | ETA: 2025-05-09 16:16:16\n",
            "--------------------------------------------------\n",
            "Processing article 2/200: joint_geometrical_and_statistical_domain_adaptation_for_cross-domain_code_vulnerability_detection\n",
            "Done in 5.73s | Avg: 12.08s | Remaining: 198 | ETA: 2025-05-09 15:55:05\n",
            "--------------------------------------------------\n",
            "Processing article 3/200: reward-augmented_decoding_efficient_controlled_text_generation_with_a_unidirectional_reward_model\n",
            "Done in 6.79s | Avg: 10.32s | Remaining: 197 | ETA: 2025-05-09 15:49:12\n",
            "--------------------------------------------------\n",
            "Processing article 4/200: InterFair__Debiasing_with_Natural_Language_Feedback_for_Fair_Interpretable_Predictions\n",
            "Done in 21.88s | Avg: 13.21s | Remaining: 196 | ETA: 2025-05-09 15:58:50\n",
            "--------------------------------------------------\n",
            "Processing article 5/200: Let’s_Think_Frame_by_Frame_with_VIP__A_Video_Infilling_and_Prediction_Dataset_for_Evaluating_Video_Chain-of-Thought\n",
            "Done in 21.51s | Avg: 14.87s | Remaining: 195 | ETA: 2025-05-09 16:04:22\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 21990 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing article 6/200: Text_Fact_Transfer\n",
            "Done in 12.59s | Avg: 14.49s | Remaining: 194 | ETA: 2025-05-09 16:03:07\n",
            "--------------------------------------------------\n",
            "Processing article 7/200: from_text_segmentation_to_smart_chaptering_a_novel_benchmark_for_structuring_video_transcriptions\n",
            "Done in 8.06s | Avg: 13.57s | Remaining: 193 | ETA: 2025-05-09 16:00:03\n",
            "--------------------------------------------------\n",
            "Processing article 8/200: automatic_dialog_flow_extraction_and_guidance\n",
            "Done in 37.20s | Avg: 16.52s | Remaining: 192 | ETA: 2025-05-09 16:09:54\n",
            "--------------------------------------------------\n",
            "Processing article 9/200: combining_a_statistical_language_model_with_logistic_regression_to_predict_the_lexical_and_syntactic_difficulty_of_texts_for_ffl\n",
            "Done in 4.94s | Avg: 15.24s | Remaining: 191 | ETA: 2025-05-09 16:05:36\n",
            "--------------------------------------------------\n",
            "Processing article 10/200: Pre-Trained_Language_Models_Augmented_with_Synthetic_Scanpaths_for_Natural_Language_Understanding\n",
            "Done in 4.50s | Avg: 14.16s | Remaining: 190 | ETA: 2025-05-09 16:02:02\n",
            "--------------------------------------------------\n",
            "Processing article 11/200: the_role_of_initiative_in_tutorial_dialogue\n",
            "Done in 26.26s | Avg: 15.26s | Remaining: 189 | ETA: 2025-05-09 16:05:42\n",
            "--------------------------------------------------\n",
            "Processing article 12/200: evaluating_unsupervised_argument_aligners_via_generation_of_conclusions_of_structured_scientific_abstracts\n",
            "Done in 25.99s | Avg: 16.16s | Remaining: 188 | ETA: 2025-05-09 16:08:41\n",
            "--------------------------------------------------\n",
            "Processing article 13/200: realistic_conversational_question_answering_with_answer_selection_based_on_calibrated_confidence_and_uncertainty_measurement\n",
            "Done in 19.01s | Avg: 16.38s | Remaining: 187 | ETA: 2025-05-09 16:09:25\n",
            "--------------------------------------------------\n",
            "Processing article 14/200: why_find_the_right_one\n",
            "Done in 22.48s | Avg: 16.81s | Remaining: 186 | ETA: 2025-05-09 16:10:52\n",
            "--------------------------------------------------\n",
            "Processing article 15/200: continuous_ngram_representations_for_authorship_attribution\n",
            "Done in 24.32s | Avg: 17.31s | Remaining: 185 | ETA: 2025-05-09 16:12:32\n",
            "--------------------------------------------------\n",
            "Processing article 16/200: event-driven_news_stream_clustering_using_entity-aware_contextual_embeddings\n",
            "Done in 36.69s | Avg: 18.52s | Remaining: 184 | ETA: 2025-05-09 16:16:35\n",
            "--------------------------------------------------\n",
            "Processing article 17/200: rethinking_and_improving_multi-task_learning_for_end-to-end_speech_translation\n",
            "Done in 11.80s | Avg: 18.13s | Remaining: 183 | ETA: 2025-05-09 16:15:16\n",
            "--------------------------------------------------\n",
            "Processing article 18/200: berxit_early_exiting_for_bert_with_better_fine-tuning_and_extension_to_regression\n",
            "Done in 7.44s | Avg: 17.53s | Remaining: 182 | ETA: 2025-05-09 16:13:17\n",
            "--------------------------------------------------\n",
            "Processing article 19/200: question-answer_sentence_graph_for_joint_modeling_answer_selection\n",
            "Done in 18.23s | Avg: 17.57s | Remaining: 181 | ETA: 2025-05-09 16:13:24\n",
            "--------------------------------------------------\n",
            "Processing article 20/200: semisupervised_semantic_role_labeling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 24331 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 32.11s | Avg: 18.30s | Remaining: 180 | ETA: 2025-05-09 16:15:50\n",
            "--------------------------------------------------\n",
            "Processing article 21/200: probing_cross-lingual_lexical_knowledge_from_multilingual_sentence_encoders\n",
            "Done in 10.95s | Avg: 17.95s | Remaining: 179 | ETA: 2025-05-09 16:14:40\n",
            "--------------------------------------------------\n",
            "Processing article 22/200: exploiting_summarization_data_to_help_text_simplification\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 18491 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 28.39s | Avg: 18.42s | Remaining: 178 | ETA: 2025-05-09 16:16:15\n",
            "--------------------------------------------------\n",
            "Processing article 23/200: This_is_not_a_Dataset__A_Large_Negation_Benchmark_to_Challenge_Large_Language_Models\n",
            "Done in 12.45s | Avg: 18.16s | Remaining: 177 | ETA: 2025-05-09 16:15:23\n",
            "--------------------------------------------------\n",
            "Processing article 24/200: pytlex_a_python_library_for_timeline_extraction\n",
            "Done in 26.79s | Avg: 18.52s | Remaining: 176 | ETA: 2025-05-09 16:16:35\n",
            "--------------------------------------------------\n",
            "Processing article 25/200: rptcs_a_reinforced_personaaware_topicguiding_conversational_system\n",
            "Done in 8.66s | Avg: 18.13s | Remaining: 175 | ETA: 2025-05-09 16:15:16\n",
            "--------------------------------------------------\n",
            "Processing article 26/200: Once_is_Enough__A_Light-Weight_Cross-Attention_for_Fast_Sentence_Pair_Modeling\n",
            "Done in 3.48s | Avg: 17.56s | Remaining: 174 | ETA: 2025-05-09 16:13:24\n",
            "--------------------------------------------------\n",
            "Processing article 27/200: propagation_strategies_for_building_temporal_ontologies\n",
            "Done in 22.60s | Avg: 17.75s | Remaining: 173 | ETA: 2025-05-09 16:14:02\n",
            "--------------------------------------------------\n",
            "Processing article 28/200: Unified_Low-Resource_Sequence_Labeling_by_Sample-Aware_Dynamic_Sparse_Finetuning\n",
            "Done in 11.79s | Avg: 17.54s | Remaining: 172 | ETA: 2025-05-09 16:13:19\n",
            "--------------------------------------------------\n",
            "Processing article 29/200: persona_expansion_with_commonsense_knowledge_for_diverse_and_consistent_response_generation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 20452 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 38.10s | Avg: 18.25s | Remaining: 171 | ETA: 2025-05-09 16:15:41\n",
            "--------------------------------------------------\n",
            "Processing article 30/200: Reasoning_with_Language_Model_is_Planning_with_World_Model\n",
            "Done in 19.13s | Avg: 18.28s | Remaining: 170 | ETA: 2025-05-09 16:15:47\n",
            "--------------------------------------------------\n",
            "Processing article 31/200: what_substitutes_tell_us__analysis_of_an_allwords_lexical_substitution_corpus\n",
            "Done in 22.17s | Avg: 18.40s | Remaining: 169 | ETA: 2025-05-09 16:16:13\n",
            "--------------------------------------------------\n",
            "Processing article 32/200: lexicalized_reordering_for_lefttoright_hierarchical_phrasebased_translation\n",
            "Done in 25.85s | Avg: 18.63s | Remaining: 168 | ETA: 2025-05-09 16:16:59\n",
            "--------------------------------------------------\n",
            "Processing article 33/200: empirical_evaluations_of_animacy_annotation\n",
            "Done in 33.37s | Avg: 19.08s | Remaining: 167 | ETA: 2025-05-09 16:18:28\n",
            "--------------------------------------------------\n",
            "Processing article 34/200: measuring_frame_relatedness\n",
            "Done in 33.29s | Avg: 19.50s | Remaining: 166 | ETA: 2025-05-09 16:19:52\n",
            "--------------------------------------------------\n",
            "Processing article 35/200: bilingually_motivated_domainadapted_word_segmentation_for_statistical_machine_translation\n",
            "Done in 30.99s | Avg: 19.83s | Remaining: 165 | ETA: 2025-05-09 16:20:58\n",
            "--------------------------------------------------\n",
            "Processing article 36/200: spindle_spinning_raw_text_into_lambda_terms_with_graph_attention\n",
            "Done in 27.96s | Avg: 20.05s | Remaining: 164 | ETA: 2025-05-09 16:21:43\n",
            "--------------------------------------------------\n",
            "Processing article 37/200: Well_Begun_is_Half_Done__Generator-agnostic_Knowledge_Pre-Selection_for_Knowledge-Grounded_Dialogue\n",
            "Done in 8.06s | Avg: 19.73s | Remaining: 163 | ETA: 2025-05-09 16:20:39\n",
            "--------------------------------------------------\n",
            "Processing article 38/200: detecting_negation_scope_is_easy_except_when_it_isn’t\n",
            "Done in 21.19s | Avg: 19.77s | Remaining: 162 | ETA: 2025-05-09 16:20:46\n",
            "--------------------------------------------------\n",
            "Processing article 39/200: exploring_different_dimensions_of_attention_for_uncertainty_detection\n",
            "Done in 22.77s | Avg: 19.84s | Remaining: 161 | ETA: 2025-05-09 16:21:02\n",
            "--------------------------------------------------\n",
            "Processing article 40/200: dictionary-based_debiasing_of_pre-trained_word_embeddings\n",
            "Done in 34.31s | Avg: 20.21s | Remaining: 160 | ETA: 2025-05-09 16:22:14\n",
            "--------------------------------------------------\n",
            "Processing article 41/200: ctc-based_compression_for_direct_speech_translation\n",
            "Done in 24.93s | Avg: 20.32s | Remaining: 159 | ETA: 2025-05-09 16:22:38\n",
            "--------------------------------------------------\n",
            "Processing article 42/200: handling_outofvocabulary_problem_in_hangeul_word_embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 17234 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 27.96s | Avg: 20.50s | Remaining: 158 | ETA: 2025-05-09 16:23:14\n",
            "--------------------------------------------------\n",
            "Processing article 43/200: privacy_implications_of_retrieval-based_language_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 16382 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 22.31s | Avg: 20.55s | Remaining: 157 | ETA: 2025-05-09 16:23:23\n",
            "--------------------------------------------------\n",
            "Processing article 44/200: LLM-FP4__4-Bit_Floating-Point_Quantized_Transformers\n",
            "Done in 35.85s | Avg: 20.89s | Remaining: 156 | ETA: 2025-05-09 16:24:32\n",
            "--------------------------------------------------\n",
            "Processing article 45/200: bart-tl_weakly-supervised_topic_label_generation\n",
            "Done in 4.34s | Avg: 20.53s | Remaining: 155 | ETA: 2025-05-09 16:23:18\n",
            "--------------------------------------------------\n",
            "Processing article 46/200: sequential_labeling_with_latent_variables_an_exact_inference_algorithm_and_its_efficient_approximation\n",
            "Done in 12.85s | Avg: 20.36s | Remaining: 154 | ETA: 2025-05-09 16:22:46\n",
            "--------------------------------------------------\n",
            "Processing article 47/200: MMNMT__Modularizing_Multilingual_Neural_Machine_Translation_with_Flexibly_Assembled_MoE_and_Dense_Blocks\n",
            "Done in 38.93s | Avg: 20.75s | Remaining: 153 | ETA: 2025-05-09 16:24:05\n",
            "--------------------------------------------------\n",
            "Processing article 48/200: Prototype-based_HyperAdapter_for_Sample-Efficient_Multi-task_Tuning\n",
            "Done in 34.35s | Avg: 21.04s | Remaining: 152 | ETA: 2025-05-09 16:25:01\n",
            "--------------------------------------------------\n",
            "Processing article 49/200: classifying_the_hungarian_web\n",
            "Done in 8.85s | Avg: 20.79s | Remaining: 151 | ETA: 2025-05-09 16:24:12\n",
            "--------------------------------------------------\n",
            "Processing article 50/200: learning_for_microblogs_with_distant_supervision_political_forecasting_with_twitter\n",
            "Done in 29.92s | Avg: 20.97s | Remaining: 150 | ETA: 2025-05-09 16:24:48\n",
            "--------------------------------------------------\n",
            "Processing article 51/200: improving_probabilistic_latent_semantic_analysis_with_principal_component_analysis\n",
            "Done in 7.25s | Avg: 20.70s | Remaining: 149 | ETA: 2025-05-09 16:23:55\n",
            "--------------------------------------------------\n",
            "Processing article 52/200: Query2doc__Query_Expansion_with_Large_Language_Models\n",
            "Done in 34.62s | Avg: 20.97s | Remaining: 148 | ETA: 2025-05-09 16:24:49\n",
            "--------------------------------------------------\n",
            "Processing article 53/200: scientific_discourse_tagging_for_evidence_extraction\n",
            "Done in 14.64s | Avg: 20.85s | Remaining: 147 | ETA: 2025-05-09 16:24:25\n",
            "--------------------------------------------------\n",
            "Processing article 54/200: largescale_evaluation_of_dependencybased_dsms_are_they_worth_the_effort\n",
            "Done in 24.98s | Avg: 20.93s | Remaining: 146 | ETA: 2025-05-09 16:24:40\n",
            "--------------------------------------------------\n",
            "Processing article 55/200: PRCA__Fitting_Black-Box_Large_Language_Models_for_Retrieval_Question_Answering_via_Pluggable_Reward-Driven_Contextual_Adapter\n",
            "Done in 9.51s | Avg: 20.72s | Remaining: 145 | ETA: 2025-05-09 16:23:59\n",
            "--------------------------------------------------\n",
            "Processing article 56/200: Unveiling_the_Implicit_Toxicity_in_Large_Language_Models\n",
            "Done in 18.14s | Avg: 20.67s | Remaining: 144 | ETA: 2025-05-09 16:23:50\n",
            "--------------------------------------------------\n",
            "Processing article 57/200: drag_director-generator_language_modelling_framework_for_non-parallel_author_stylized_rewriting\n",
            "Done in 37.53s | Avg: 20.97s | Remaining: 143 | ETA: 2025-05-09 16:24:49\n",
            "--------------------------------------------------\n",
            "Processing article 58/200: can_click_patterns_across_users_query_logs_predict_answers_to_definition_questions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 17223 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 33.27s | Avg: 21.18s | Remaining: 142 | ETA: 2025-05-09 16:25:32\n",
            "--------------------------------------------------\n",
            "Processing article 59/200: Speak,_Memory__An_Archaeology_of_Books_Known_to_ChatGPT_GPT-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 19340 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 18.23s | Avg: 21.13s | Remaining: 141 | ETA: 2025-05-09 16:25:22\n",
            "--------------------------------------------------\n",
            "Processing article 60/200: task-adaptive_tokenization_enhancing_long-form_text_generation_efficacy_in_mental_health_and_beyond\n",
            "Done in 10.30s | Avg: 20.95s | Remaining: 140 | ETA: 2025-05-09 16:24:46\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 16568 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing article 61/200: keep_learning_self-supervised_meta-learning_for_learning_from_inference\n",
            "Done in 22.64s | Avg: 20.98s | Remaining: 139 | ETA: 2025-05-09 16:24:52\n",
            "--------------------------------------------------\n",
            "Processing article 62/200: ellipsis_resolution_as_question_answering_an_evaluation\n",
            "Done in 10.04s | Avg: 20.80s | Remaining: 138 | ETA: 2025-05-09 16:24:17\n",
            "--------------------------------------------------\n",
            "Processing article 63/200: Log-FGAER__Logic-Guided_Fine-Grained_Address_Entity_Recognition_from_Multi-Turn_Spoken_Dialogue\n",
            "Done in 34.40s | Avg: 21.02s | Remaining: 137 | ETA: 2025-05-09 16:25:00\n",
            "--------------------------------------------------\n",
            "Processing article 64/200: probabilistic_robustness_for_data_filtering\n",
            "Done in 7.03s | Avg: 20.80s | Remaining: 136 | ETA: 2025-05-09 16:24:16\n",
            "--------------------------------------------------\n",
            "Processing article 65/200: a_probabilistic_answer_type_model\n",
            "Done in 30.47s | Avg: 20.95s | Remaining: 135 | ETA: 2025-05-09 16:24:46\n",
            "--------------------------------------------------\n",
            "Processing article 66/200: udapdr_unsupervised_domain_adaptation_via_llm_prompting_and_distillation_of_rerankers\n",
            "Done in 10.58s | Avg: 20.79s | Remaining: 134 | ETA: 2025-05-09 16:24:15\n",
            "--------------------------------------------------\n",
            "Processing article 67/200: unsupervised_methods_for_head_assignments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 17141 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 4.81s | Avg: 20.55s | Remaining: 133 | ETA: 2025-05-09 16:23:28\n",
            "--------------------------------------------------\n",
            "Processing article 68/200: ZGUL__Zero-shot_Generalization_to_Unseen_Languages_using_Multi-source_Ensembling_of_Language_Adapters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 17197 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 14.73s | Avg: 20.47s | Remaining: 132 | ETA: 2025-05-09 16:23:10\n",
            "--------------------------------------------------\n",
            "Processing article 69/200: robustification_of_multilingual_language_models_to_real-world_noise_in_crosslingual_zero-shot_settings_with_robust_contrastive_pretraining\n",
            "Done in 17.86s | Avg: 20.43s | Remaining: 131 | ETA: 2025-05-09 16:23:03\n",
            "--------------------------------------------------\n",
            "Processing article 70/200: do_deep_neural_networks_capture_compositionality_in_arithmetic_reasoning_\n",
            "Done in 37.61s | Avg: 20.67s | Remaining: 130 | ETA: 2025-05-09 16:23:52\n",
            "--------------------------------------------------\n",
            "Processing article 71/200: Length_is_a_Curse_and_a_Blessing_for_Document-level_Semantics\n",
            "Done in 8.63s | Avg: 20.50s | Remaining: 129 | ETA: 2025-05-09 16:23:19\n",
            "--------------------------------------------------\n",
            "Processing article 72/200: Improving_Biomedical_Abstractive_Summarisation_with_Knowledge_Aggregation_from_Citation_Papers\n",
            "Done in 9.89s | Avg: 20.36s | Remaining: 128 | ETA: 2025-05-09 16:22:49\n",
            "--------------------------------------------------\n",
            "Processing article 73/200: transahead_a_writing_assistant_for_cat_and_call\n",
            "Done in 4.96s | Avg: 20.15s | Remaining: 127 | ETA: 2025-05-09 16:22:07\n",
            "--------------------------------------------------\n",
            "Processing article 74/200: covid-vts_fact_extraction_and_verification_on_short_video_platforms\n",
            "Done in 8.30s | Avg: 19.99s | Remaining: 126 | ETA: 2025-05-09 16:21:35\n",
            "--------------------------------------------------\n",
            "Processing article 75/200: adaptive_fusion_techniques_for_multimodal_data\n",
            "Done in 8.06s | Avg: 19.83s | Remaining: 125 | ETA: 2025-05-09 16:21:03\n",
            "--------------------------------------------------\n",
            "Processing article 76/200: boosting_low-resource_biomedical_qa_via_entity-aware_masking_strategies\n",
            "Done in 24.54s | Avg: 19.89s | Remaining: 124 | ETA: 2025-05-09 16:21:16\n",
            "--------------------------------------------------\n",
            "Processing article 77/200: text_embeddings_reveal_(almost)_as_much_as_text\n",
            "Done in 7.02s | Avg: 19.72s | Remaining: 123 | ETA: 2025-05-09 16:20:43\n",
            "--------------------------------------------------\n",
            "Processing article 78/200: comparing_automatic_and_human_evaluation_of_nlg_systems\n",
            "Done in 29.06s | Avg: 19.84s | Remaining: 122 | ETA: 2025-05-09 16:21:07\n",
            "--------------------------------------------------\n",
            "Processing article 79/200: characterbased_pivot_translation_for_underresourced_languages_and_domains\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 16330 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 36.91s | Avg: 20.06s | Remaining: 121 | ETA: 2025-05-09 16:21:50\n",
            "--------------------------------------------------\n",
            "Processing article 80/200: frequency-guided_word_substitutions_for_detecting_textual_adversarial_examples\n",
            "Done in 12.21s | Avg: 19.96s | Remaining: 120 | ETA: 2025-05-09 16:21:30\n",
            "--------------------------------------------------\n",
            "Processing article 81/200: lightly_supervised_transliteration_for_machine_translation\n",
            "Done in 4.83s | Avg: 19.77s | Remaining: 119 | ETA: 2025-05-09 16:20:54\n",
            "--------------------------------------------------\n",
            "Processing article 82/200: We_Need_to_Talk_About_Reproducibility_in_NLP_Model_Comparison\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 16066 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 9.00s | Avg: 19.64s | Remaining: 118 | ETA: 2025-05-09 16:20:27\n",
            "--------------------------------------------------\n",
            "Processing article 83/200: SelfCheckGPT__Zero-Resource_Black-Box_Hallucination_Detection_for_Generative_Large_Language_Models\n",
            "Done in 12.71s | Avg: 19.56s | Remaining: 117 | ETA: 2025-05-09 16:20:11\n",
            "--------------------------------------------------\n",
            "Processing article 84/200: instances_and_concepts_in_distributional_space\n",
            "Done in 26.05s | Avg: 19.63s | Remaining: 116 | ETA: 2025-05-09 16:20:26\n",
            "--------------------------------------------------\n",
            "Processing article 85/200: the_impacts_of_unanswerable_questions_on_the_robustness_of_machine_reading_comprehension_models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 16372 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 9.33s | Avg: 19.51s | Remaining: 115 | ETA: 2025-05-09 16:20:02\n",
            "--------------------------------------------------\n",
            "Processing article 86/200: multilingual_pixel_representations_for_translation_and_effective_cross-lingual_transfer\n",
            "Done in 14.44s | Avg: 19.45s | Remaining: 114 | ETA: 2025-05-09 16:19:51\n",
            "--------------------------------------------------\n",
            "Processing article 87/200: a_multitask_approach_to_predict_likability_of_books\n",
            "Done in 36.45s | Avg: 19.65s | Remaining: 113 | ETA: 2025-05-09 16:20:30\n",
            "--------------------------------------------------\n",
            "Processing article 88/200: bootstrapping_named_entity_recognition_with_automatically_generated_gazetteer_lists\n",
            "Done in 25.24s | Avg: 19.71s | Remaining: 112 | ETA: 2025-05-09 16:20:43\n",
            "--------------------------------------------------\n",
            "Processing article 89/200: openpi2.0_an_improved_dataset_for_entity_tracking_in_texts\n",
            "Done in 7.71s | Avg: 19.58s | Remaining: 111 | ETA: 2025-05-09 16:20:16\n",
            "--------------------------------------------------\n",
            "Processing article 90/200: classifying_illegal_activities_on_tor_network_based_on_web_textual_contents\n",
            "Done in 5.94s | Avg: 19.43s | Remaining: 110 | ETA: 2025-05-09 16:19:45\n",
            "--------------------------------------------------\n",
            "Processing article 91/200: zero_subject_detection_for_polish\n",
            "Done in 5.72s | Avg: 19.28s | Remaining: 109 | ETA: 2025-05-09 16:19:16\n",
            "--------------------------------------------------\n",
            "Processing article 92/200: randomized_deep_structured_prediction_for_discourse-level_processing\n",
            "Done in 40.70s | Avg: 19.51s | Remaining: 108 | ETA: 2025-05-09 16:20:02\n",
            "--------------------------------------------------\n",
            "Processing article 93/200: mRedditSum__A_Multimodal_Abstractive_Summarization_Dataset_of_Reddit_Threads_with_Images\n",
            "Done in 11.20s | Avg: 19.42s | Remaining: 107 | ETA: 2025-05-09 16:19:44\n",
            "--------------------------------------------------\n",
            "Processing article 94/200: ranking_convolutional_recurrent_neural_networks_for_purchase_stage_identification_on_imbalanced_twitter_data\n",
            "Done in 25.01s | Avg: 19.48s | Remaining: 106 | ETA: 2025-05-09 16:19:56\n",
            "--------------------------------------------------\n",
            "Processing article 95/200: prompt_as_triggers_for_backdoor_attack_examining_the_vulnerability_in_language_models\n",
            "Done in 14.72s | Avg: 19.43s | Remaining: 105 | ETA: 2025-05-09 16:19:46\n",
            "--------------------------------------------------\n",
            "Processing article 96/200: data_augmentation_for_voice-assistant_nlu_using_bert-based_interchangeable_rephrase\n",
            "Done in 27.76s | Avg: 19.52s | Remaining: 104 | ETA: 2025-05-09 16:20:04\n",
            "--------------------------------------------------\n",
            "Processing article 97/200: coreference_resolution_evaluation_for_higher_level_applications\n",
            "Done in 20.79s | Avg: 19.53s | Remaining: 103 | ETA: 2025-05-09 16:20:07\n",
            "--------------------------------------------------\n",
            "Processing article 98/200: Target-oriented_Proactive_Dialogue_Systems_with_Personalization__Problem_Formulation_and_Dataset_Curation\n",
            "Done in 34.81s | Avg: 19.69s | Remaining: 102 | ETA: 2025-05-09 16:20:38\n",
            "--------------------------------------------------\n",
            "Processing article 99/200: a_dataoriented_model_of_literary_language\n",
            "Done in 35.46s | Avg: 19.84s | Remaining: 101 | ETA: 2025-05-09 16:21:10\n",
            "--------------------------------------------------\n",
            "Processing article 100/200: exploring_supervised_and_unsupervised_rewards_in_machine_translation\n",
            "Done in 26.36s | Avg: 19.91s | Remaining: 100 | ETA: 2025-05-09 16:21:23\n",
            "--------------------------------------------------\n",
            "Processing article 101/200: stereotype_and_skew_quantifying_gender_bias_in_pre-trained_and_fine-tuned_language_models\n",
            "Done in 36.27s | Avg: 20.07s | Remaining: 99 | ETA: 2025-05-09 16:21:56\n",
            "--------------------------------------------------\n",
            "Processing article 102/200: end-to-end_argument_mining_as_biaffine_dependency_parsing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 27507 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 34.51s | Avg: 20.21s | Remaining: 98 | ETA: 2025-05-09 16:22:24\n",
            "--------------------------------------------------\n",
            "Processing article 103/200: generationbased_data_augmentation_for_offensive_language_detection_is_it_worth_it\n",
            "Done in 13.28s | Avg: 20.15s | Remaining: 97 | ETA: 2025-05-09 16:22:11\n",
            "--------------------------------------------------\n",
            "Processing article 104/200: mint_a_method_for_effective_and_scalable_mining_of_named_entity_transliterations_from_large_comparable_corpora\n",
            "Done in 6.43s | Avg: 20.01s | Remaining: 96 | ETA: 2025-05-09 16:21:45\n",
            "--------------------------------------------------\n",
            "Processing article 105/200: disfluency_correction_using_unsupervised_and_semisupervised_learning\n",
            "Done in 26.34s | Avg: 20.07s | Remaining: 95 | ETA: 2025-05-09 16:21:57\n",
            "--------------------------------------------------\n",
            "Processing article 106/200: we_need_to_talk_about_random_splits\n",
            "Done in 5.78s | Avg: 19.94s | Remaining: 94 | ETA: 2025-05-09 16:21:30\n",
            "--------------------------------------------------\n",
            "Processing article 107/200: watsl_a_customizable_web_annotation_tool_for_segment_labeling\n",
            "Done in 18.71s | Avg: 19.93s | Remaining: 93 | ETA: 2025-05-09 16:21:28\n",
            "--------------------------------------------------\n",
            "Processing article 108/200: fast_financial_news_and_tweet_based_time_aware_network_for_stock_trading\n",
            "Done in 9.25s | Avg: 19.83s | Remaining: 92 | ETA: 2025-05-09 16:21:08\n",
            "--------------------------------------------------\n",
            "Processing article 109/200: elleipo_a_module_that_computes_coordinative_ellipsis_for_generators_that_dont\n",
            "Done in 18.99s | Avg: 19.82s | Remaining: 91 | ETA: 2025-05-09 16:21:07\n",
            "--------------------------------------------------\n",
            "Processing article 110/200: contextual_dynamic_prompting_for_response_generation_in_taskoriented_dialog_systems\n",
            "Done in 7.88s | Avg: 19.71s | Remaining: 90 | ETA: 2025-05-09 16:20:45\n",
            "--------------------------------------------------\n",
            "Processing article 111/200: single_and_crossdomain_polarity_classification_using_string_kernels\n",
            "Done in 21.05s | Avg: 19.73s | Remaining: 89 | ETA: 2025-05-09 16:20:48\n",
            "--------------------------------------------------\n",
            "Processing article 112/200: Whispering_LLaMA__A_Cross-Modal_Generative_Error_Correction_Framework_for_Speech_Recognition\n",
            "Done in 34.96s | Avg: 19.86s | Remaining: 88 | ETA: 2025-05-09 16:21:15\n",
            "--------------------------------------------------\n",
            "Processing article 113/200: addressing_domain_changes_in_taskoriented_conversational_agents_through_dialogue_adaptation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 16465 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 4.91s | Avg: 19.73s | Remaining: 87 | ETA: 2025-05-09 16:20:49\n",
            "--------------------------------------------------\n",
            "Processing article 114/200: Lifelong_Sequence_Generation_with_Dynamic_Module_Expansion_and_Adaptation\n",
            "Done in 15.11s | Avg: 19.69s | Remaining: 86 | ETA: 2025-05-09 16:20:41\n",
            "--------------------------------------------------\n",
            "Processing article 115/200: computational_complexity_of_statistical_machine_translation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 16085 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 5.57s | Avg: 19.57s | Remaining: 85 | ETA: 2025-05-09 16:20:16\n",
            "--------------------------------------------------\n",
            "Processing article 116/200: ReasoningLM__Enabling_Structural_Subgraph_Reasoning_in_Pre-trained_Language_Models_for_Question_Answering_over_Knowledge_Graph\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 16570 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 37.19s | Avg: 19.72s | Remaining: 84 | ETA: 2025-05-09 16:20:47\n",
            "--------------------------------------------------\n",
            "Processing article 117/200: largescale_label_interpretation_learning_for_fewshot_named_entity_recognition\n",
            "Done in 20.76s | Avg: 19.73s | Remaining: 83 | ETA: 2025-05-09 16:20:49\n",
            "--------------------------------------------------\n",
            "Processing article 118/200: sentiment_summarization_evaluating_and_learning_user_preferences\n",
            "Done in 6.76s | Avg: 19.62s | Remaining: 82 | ETA: 2025-05-09 16:20:27\n",
            "--------------------------------------------------\n",
            "Processing article 119/200: pdf\n",
            "Done in 38.00s | Avg: 19.77s | Remaining: 81 | ETA: 2025-05-09 16:20:58\n",
            "--------------------------------------------------\n",
            "Processing article 120/200: Retrofitting_Light-weight_Language_Models_for_Emotions_using_Supervised_Contrastive_Learning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 18577 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 18.57s | Avg: 19.76s | Remaining: 80 | ETA: 2025-05-09 16:20:56\n",
            "--------------------------------------------------\n",
            "Processing article 121/200: towards_a_decomposable_metric_for_explainable_evaluation_of_text_generation_from_amr\n",
            "Done in 14.83s | Avg: 19.72s | Remaining: 79 | ETA: 2025-05-09 16:20:48\n",
            "--------------------------------------------------\n",
            "Processing article 122/200: on_the_benefits_of_finegrained_loss_truncation_a_case_study_on_factuality_in_summarization\n",
            "Done in 39.66s | Avg: 19.88s | Remaining: 78 | ETA: 2025-05-09 16:21:21\n",
            "--------------------------------------------------\n",
            "Processing article 123/200: Language_Model_Quality_Correlates_with_Psychometric_Predictive_Power_in_Multiple_Languages\n",
            "Done in 34.24s | Avg: 20.00s | Remaining: 77 | ETA: 2025-05-09 16:21:44\n",
            "--------------------------------------------------\n",
            "Processing article 124/200: keeping_the_initiative_an_empiricallymotivated_approach_to_predicting_userinitiated_dialogue_contribution_in_hci\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 18138 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 8.84s | Avg: 19.91s | Remaining: 76 | ETA: 2025-05-09 16:21:26\n",
            "--------------------------------------------------\n",
            "Processing article 125/200: document_structure_in_long_document_transformers\n",
            "Done in 13.87s | Avg: 19.86s | Remaining: 75 | ETA: 2025-05-09 16:21:17\n",
            "--------------------------------------------------\n",
            "Processing article 126/200: uprise_universal_prompt_retrieval_for_improving_zero-shot_evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 19900 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 12.70s | Avg: 19.81s | Remaining: 74 | ETA: 2025-05-09 16:21:06\n",
            "--------------------------------------------------\n",
            "Processing article 127/200: ZEROTOP__Zero-Shot_Task-Oriented_Semantic_Parsing_using_Large_Language_Models\n",
            "Done in 17.68s | Avg: 19.79s | Remaining: 73 | ETA: 2025-05-09 16:21:03\n",
            "--------------------------------------------------\n",
            "Processing article 128/200: computing_term_translation_probabilities_with_generalized_latent_semantic_analysis\n",
            "Done in 18.22s | Avg: 19.78s | Remaining: 72 | ETA: 2025-05-09 16:21:00\n",
            "--------------------------------------------------\n",
            "Processing article 129/200: is_machine_translation_getting_better_over_time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 19858 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 5.26s | Avg: 19.66s | Remaining: 71 | ETA: 2025-05-09 16:20:38\n",
            "--------------------------------------------------\n",
            "Processing article 130/200: bias_in_opinion_summarisation_from_pre-training_to_adaptation_a_case_study_in_political_bias\n",
            "Done in 10.85s | Avg: 19.60s | Remaining: 70 | ETA: 2025-05-09 16:20:24\n",
            "--------------------------------------------------\n",
            "Processing article 131/200: target-to-source_augmentation_for_aspect_sentiment_triplet_extraction\n",
            "Done in 27.94s | Avg: 19.66s | Remaining: 69 | ETA: 2025-05-09 16:20:38\n",
            "--------------------------------------------------\n",
            "Processing article 132/200: a_joint_model_for_quotation_attribution_and_coreference_resolution\n",
            "Done in 12.55s | Avg: 19.61s | Remaining: 68 | ETA: 2025-05-09 16:20:27\n",
            "--------------------------------------------------\n",
            "Processing article 133/200: large_language_models_are_complex_table_parsers\n",
            "Done in 8.08s | Avg: 19.52s | Remaining: 67 | ETA: 2025-05-09 16:20:10\n",
            "--------------------------------------------------\n",
            "Processing article 134/200: translation_errors_significantly_impact_lowresource_languages_in_crosslingual_learning\n",
            "Done in 12.01s | Avg: 19.46s | Remaining: 66 | ETA: 2025-05-09 16:19:58\n",
            "--------------------------------------------------\n",
            "Processing article 135/200: from_segmentation_to_analyses_a_probabilistic_model_for_unsupervised_morphology_induction\n",
            "Done in 34.38s | Avg: 19.57s | Remaining: 65 | ETA: 2025-05-09 16:20:21\n",
            "--------------------------------------------------\n",
            "Processing article 136/200: frequency_matters_pitch_accents_and_information_status\n",
            "Done in 31.45s | Avg: 19.66s | Remaining: 64 | ETA: 2025-05-09 16:20:39\n",
            "--------------------------------------------------\n",
            "Processing article 137/200: esfinge__a_question_answering_system_in_the_web_using_the_web\n",
            "Done in 20.10s | Avg: 19.66s | Remaining: 63 | ETA: 2025-05-09 16:20:39\n",
            "--------------------------------------------------\n",
            "Processing article 138/200: polarized_opinion_detection_improves_the_detection_of_toxic_language\n",
            "Done in 8.87s | Avg: 19.59s | Remaining: 62 | ETA: 2025-05-09 16:20:24\n",
            "--------------------------------------------------\n",
            "Processing article 139/200: OssCSE__Overcoming_Surface_Structure_Bias_in_Contrastive_Learning_for_Unsupervised_Sentence_Embedding\n",
            "Done in 12.03s | Avg: 19.53s | Remaining: 61 | ETA: 2025-05-09 16:20:13\n",
            "--------------------------------------------------\n",
            "Processing article 140/200: folheador_browsing_through_portuguese_semantic_relations\n",
            "Done in 21.88s | Avg: 19.55s | Remaining: 60 | ETA: 2025-05-09 16:20:16\n",
            "--------------------------------------------------\n",
            "Processing article 141/200: logic_against_bias_textual_entailment_mitigates_stereotypical_sentence_reasoning\n",
            "Done in 40.37s | Avg: 19.70s | Remaining: 59 | ETA: 2025-05-09 16:20:46\n",
            "--------------------------------------------------\n",
            "Processing article 142/200: on_the_calibration_and_uncertainty_of_neural_learning_to_rank_models_for_conversational_search\n",
            "Done in 9.49s | Avg: 19.62s | Remaining: 58 | ETA: 2025-05-09 16:20:32\n",
            "--------------------------------------------------\n",
            "Processing article 143/200: lexicalising_word_order_constraints_for_implemented_linearisation_grammar\n",
            "Done in 11.57s | Avg: 19.57s | Remaining: 57 | ETA: 2025-05-09 16:20:21\n",
            "--------------------------------------------------\n",
            "Processing article 144/200: INFORM___Information_eNtropy_based_multi-step_reasoning_FOR_large_language_Models\n",
            "Done in 6.48s | Avg: 19.48s | Remaining: 56 | ETA: 2025-05-09 16:20:02\n",
            "--------------------------------------------------\n",
            "Processing article 145/200: cdˆ2cr_co-reference_resolution_across_documents_and_domains\n",
            "Done in 36.02s | Avg: 19.59s | Remaining: 55 | ETA: 2025-05-09 16:20:25\n",
            "--------------------------------------------------\n",
            "Processing article 146/200: largecoverage_root_lexicon_extraction_for_hindi\n",
            "Done in 8.99s | Avg: 19.52s | Remaining: 54 | ETA: 2025-05-09 16:20:11\n",
            "--------------------------------------------------\n",
            "Processing article 147/200: gapgen_guided_automatic_python_code_generation\n",
            "Done in 10.55s | Avg: 19.46s | Remaining: 53 | ETA: 2025-05-09 16:19:59\n",
            "--------------------------------------------------\n",
            "Processing article 148/200: multilingual_call_framework_for_automatic_language_exercise_generation_from_free_text\n",
            "Done in 18.73s | Avg: 19.45s | Remaining: 52 | ETA: 2025-05-09 16:19:58\n",
            "--------------------------------------------------\n",
            "Processing article 149/200: addressee_identification_in_facetoface_meetings\n",
            "Done in 29.65s | Avg: 19.52s | Remaining: 51 | ETA: 2025-05-09 16:20:12\n",
            "--------------------------------------------------\n",
            "Processing article 150/200: incremental_beam_manipulation_for_natural_language_generation\n",
            "Done in 36.69s | Avg: 19.64s | Remaining: 50 | ETA: 2025-05-09 16:20:35\n",
            "--------------------------------------------------\n",
            "Processing article 151/200: Understanding_the_Effect_of_Model_Compression_on_Social_Bias_in_Large_Language_Models\n",
            "Done in 38.95s | Avg: 19.76s | Remaining: 49 | ETA: 2025-05-09 16:21:01\n",
            "--------------------------------------------------\n",
            "Processing article 152/200: globalbench_a_benchmark_for_global_progress_in_natural_language_processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 19477 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 14.52s | Avg: 19.73s | Remaining: 48 | ETA: 2025-05-09 16:20:54\n",
            "--------------------------------------------------\n",
            "Processing article 153/200: Knowledge-Augmented_Language_Model_Verification\n",
            "Done in 10.83s | Avg: 19.67s | Remaining: 47 | ETA: 2025-05-09 16:20:42\n",
            "--------------------------------------------------\n",
            "Processing article 154/200: chinese_native_language_identification\n",
            "Done in 3.63s | Avg: 19.57s | Remaining: 46 | ETA: 2025-05-09 16:20:22\n",
            "--------------------------------------------------\n",
            "Processing article 155/200: covrelexse_adding_semantic_information_for_relation_search_via_sequence_embedding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 17460 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 26.92s | Avg: 19.61s | Remaining: 45 | ETA: 2025-05-09 16:20:31\n",
            "--------------------------------------------------\n",
            "Processing article 156/200: Transfer-Free_Data-Efficient_Multilingual_Slot_Labeling\n",
            "Done in 17.53s | Avg: 19.60s | Remaining: 44 | ETA: 2025-05-09 16:20:29\n",
            "--------------------------------------------------\n",
            "Processing article 157/200: bert_is_not_the_count_learning_to_match_mathematical_statements_with_proofs\n",
            "Done in 15.43s | Avg: 19.57s | Remaining: 43 | ETA: 2025-05-09 16:20:24\n",
            "--------------------------------------------------\n",
            "Processing article 158/200: a_phonetic_model_of_non-native_spoken_word_processing\n",
            "Done in 38.04s | Avg: 19.69s | Remaining: 42 | ETA: 2025-05-09 16:20:47\n",
            "--------------------------------------------------\n",
            "Processing article 159/200: hop_union_generate_explainable_multihop_reasoning_without_rationale_supervision\n",
            "Done in 28.30s | Avg: 19.74s | Remaining: 41 | ETA: 2025-05-09 16:20:58\n",
            "--------------------------------------------------\n",
            "Processing article 160/200: learning_to_predict_denotational_probabilities_for_modeling_entailment\n",
            "Done in 8.65s | Avg: 19.68s | Remaining: 40 | ETA: 2025-05-09 16:20:44\n",
            "--------------------------------------------------\n",
            "Processing article 161/200: pretraining_methods_for_question_reranking\n",
            "Done in 5.39s | Avg: 19.59s | Remaining: 39 | ETA: 2025-05-09 16:20:27\n",
            "--------------------------------------------------\n",
            "Processing article 162/200: yet_another_language_identifier\n",
            "Done in 31.25s | Avg: 19.66s | Remaining: 38 | ETA: 2025-05-09 16:20:41\n",
            "--------------------------------------------------\n",
            "Processing article 163/200: SKD-NER__Continual_Named_Entity_Recognition_via_Span-based_Knowledge_Distillation_with_Reinforcement_Learning\n",
            "Done in 37.73s | Avg: 19.77s | Remaining: 37 | ETA: 2025-05-09 16:21:03\n",
            "--------------------------------------------------\n",
            "Processing article 164/200: representing_elmo_embeddings_as_twodimensional_text_online\n",
            "Done in 21.26s | Avg: 19.78s | Remaining: 36 | ETA: 2025-05-09 16:21:05\n",
            "--------------------------------------------------\n",
            "Processing article 165/200: bert_shows_garden_path_effects\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 16337 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 5.83s | Avg: 19.69s | Remaining: 35 | ETA: 2025-05-09 16:20:48\n",
            "--------------------------------------------------\n",
            "Processing article 166/200: glara_graphbased_labeling_rule_augmentation_for_weakly_supervised_named_entity_recognition\n",
            "Done in 23.17s | Avg: 19.72s | Remaining: 34 | ETA: 2025-05-09 16:20:53\n",
            "--------------------------------------------------\n",
            "Processing article 167/200: weighted_krippendorffs_alpha_is_a_more_reliable_metrics_for_multicoders_ordinal_annotations_experimental_studies_on_emotion_opinion_and_coreference_annotation\n",
            "Done in 33.58s | Avg: 19.80s | Remaining: 33 | ETA: 2025-05-09 16:21:10\n",
            "--------------------------------------------------\n",
            "Processing article 168/200: What_do_Deck_Chairs_and_Sun_Hats_Have_in_Common__Uncovering_Shared_Properties_in_Large_Concept_Vocabularies\n",
            "Done in 35.65s | Avg: 19.89s | Remaining: 32 | ETA: 2025-05-09 16:21:29\n",
            "--------------------------------------------------\n",
            "Processing article 169/200: parasci_a_large_scientific_paraphrase_dataset_for_longer_paraphrase_generation\n",
            "Done in 16.89s | Avg: 19.87s | Remaining: 31 | ETA: 2025-05-09 16:21:25\n",
            "--------------------------------------------------\n",
            "Processing article 170/200: learning_the_legibility_of_visual_text_perturbations\n",
            "Done in 22.06s | Avg: 19.89s | Remaining: 30 | ETA: 2025-05-09 16:21:28\n",
            "--------------------------------------------------\n",
            "Processing article 171/200: leveraging_verbargument_structures_to_infer_semantic_relations\n",
            "Done in 25.64s | Avg: 19.92s | Remaining: 29 | ETA: 2025-05-09 16:21:35\n",
            "--------------------------------------------------\n",
            "Processing article 172/200: just_title_it_by_an_online_application\n",
            "Done in 18.92s | Avg: 19.92s | Remaining: 28 | ETA: 2025-05-09 16:21:34\n",
            "--------------------------------------------------\n",
            "Processing article 173/200: transparent_combination_of_rulebased_and_datadriven_approaches_in_speech_understanding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 19321 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 24.97s | Avg: 19.94s | Remaining: 27 | ETA: 2025-05-09 16:21:40\n",
            "--------------------------------------------------\n",
            "Processing article 174/200: how_transferable_are_attribute_controllers_on_pretrained_multilingual_translation_models_\n",
            "Done in 12.91s | Avg: 19.90s | Remaining: 26 | ETA: 2025-05-09 16:21:32\n",
            "--------------------------------------------------\n",
            "Processing article 175/200: generating_artificial_errors_for_grammatical_error_correction\n",
            "Done in 17.01s | Avg: 19.89s | Remaining: 25 | ETA: 2025-05-09 16:21:28\n",
            "--------------------------------------------------\n",
            "Processing article 176/200: person_identification_from_text_and_speech_genre_samples\n",
            "Done in 29.58s | Avg: 19.94s | Remaining: 24 | ETA: 2025-05-09 16:21:40\n",
            "--------------------------------------------------\n",
            "Processing article 177/200: crosslingual_tagger_evaluation_without_test_data\n",
            "Done in 26.10s | Avg: 19.98s | Remaining: 23 | ETA: 2025-05-09 16:21:47\n",
            "--------------------------------------------------\n",
            "Processing article 178/200: applying_the_semantics_of_negation_to_smt_through_nbest_list_reranking\n",
            "Done in 29.89s | Avg: 20.03s | Remaining: 22 | ETA: 2025-05-09 16:21:58\n",
            "--------------------------------------------------\n",
            "Processing article 179/200: newsmtsc_a_dataset_for_(multi-)target-dependent_sentiment_classification_in_political_news_articles\n",
            "Done in 46.14s | Avg: 20.18s | Remaining: 21 | ETA: 2025-05-09 16:22:27\n",
            "--------------------------------------------------\n",
            "Processing article 180/200: a_multiview_sentiment_corpus\n",
            "Done in 24.89s | Avg: 20.21s | Remaining: 20 | ETA: 2025-05-09 16:22:32\n",
            "--------------------------------------------------\n",
            "Processing article 181/200: increasing_robustness_to_spurious_correlations_using_forgettable_examples\n",
            "Done in 19.60s | Avg: 20.20s | Remaining: 19 | ETA: 2025-05-09 16:22:32\n",
            "--------------------------------------------------\n",
            "Processing article 182/200: unleashing_the_power_of_discourseenhanced_transformers_for_propaganda_detection\n",
            "Done in 18.12s | Avg: 20.19s | Remaining: 18 | ETA: 2025-05-09 16:22:30\n",
            "--------------------------------------------------\n",
            "Processing article 183/200: word_lattices_for_multisource_translation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 18744 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 4.51s | Avg: 20.10s | Remaining: 17 | ETA: 2025-05-09 16:22:13\n",
            "--------------------------------------------------\n",
            "Processing article 184/200: systemlevel_natural_language_feedback\n",
            "Done in 13.24s | Avg: 20.07s | Remaining: 16 | ETA: 2025-05-09 16:22:05\n",
            "--------------------------------------------------\n",
            "Processing article 185/200: lsoie_a_large-scale_dataset_for_supervised_open_information_extraction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 16854 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 22.78s | Avg: 20.08s | Remaining: 15 | ETA: 2025-05-09 16:22:08\n",
            "--------------------------------------------------\n",
            "Processing article 186/200: Sociocultural_Norm_Similarities_and_Differences_via_Situational_Alignment_and_Explainable_Textual_Entailment\n",
            "Done in 10.90s | Avg: 20.03s | Remaining: 14 | ETA: 2025-05-09 16:21:59\n",
            "--------------------------------------------------\n",
            "Processing article 187/200: generative_dense_retrieval_memory_can_be_a_burden\n",
            "Done in 38.14s | Avg: 20.13s | Remaining: 13 | ETA: 2025-05-09 16:22:19\n",
            "--------------------------------------------------\n",
            "Processing article 188/200: instancedriven_attachment_of_semantic_annotations_over_conceptual_hierarchies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 18974 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 18.25s | Avg: 20.12s | Remaining: 12 | ETA: 2025-05-09 16:22:17\n",
            "--------------------------------------------------\n",
            "Processing article 189/200: Using_Interpretation_Methods_for_Model_Enhancement\n",
            "Done in 12.14s | Avg: 20.08s | Remaining: 11 | ETA: 2025-05-09 16:22:08\n",
            "--------------------------------------------------\n",
            "Processing article 190/200: theoretical_evaluation_of_estimation_methods_for_dataoriented_parsing\n",
            "Done in 19.37s | Avg: 20.07s | Remaining: 10 | ETA: 2025-05-09 16:22:07\n",
            "--------------------------------------------------\n",
            "Processing article 191/200: anisotropy_is_inherent_to_selfattention_in_transformers\n",
            "Done in 35.80s | Avg: 20.16s | Remaining: 9 | ETA: 2025-05-09 16:22:25\n",
            "--------------------------------------------------\n",
            "Processing article 192/200: cognitionaware_cognate_detection\n",
            "Done in 41.57s | Avg: 20.27s | Remaining: 8 | ETA: 2025-05-09 16:22:47\n",
            "--------------------------------------------------\n",
            "Processing article 193/200: manually_constructed_contextfree_grammar_for_myanmar_syllable_structure\n",
            "Done in 2.60s | Avg: 20.18s | Remaining: 7 | ETA: 2025-05-09 16:22:29\n",
            "--------------------------------------------------\n",
            "Processing article 194/200: how_to_evaluate_a_summarizer_study_design_and_statistical_analysis_for_manual_linguistic_quality_evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 17880 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 36.85s | Avg: 20.26s | Remaining: 6 | ETA: 2025-05-09 16:22:46\n",
            "--------------------------------------------------\n",
            "Processing article 195/200: an_empirical_analysis_of_diversity_in_argument_summarization\n",
            "Done in 12.64s | Avg: 20.22s | Remaining: 5 | ETA: 2025-05-09 16:22:38\n",
            "--------------------------------------------------\n",
            "Processing article 196/200: assist_automated_semantic_assistance_for_translators\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 20190 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 18.45s | Avg: 20.21s | Remaining: 4 | ETA: 2025-05-09 16:22:37\n",
            "--------------------------------------------------\n",
            "Processing article 197/200: interventional_rationalization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Input IDs of length 18860 > the model's max sequence length of 16000.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 14.99s | Avg: 20.19s | Remaining: 3 | ETA: 2025-05-09 16:22:32\n",
            "--------------------------------------------------\n",
            "Processing article 198/200: Lost_in_Translation,_Found_in_Spans__Identifying_Claims_in_Multilingual_Social_Media\n",
            "Done in 9.97s | Avg: 20.14s | Remaining: 2 | ETA: 2025-05-09 16:22:21\n",
            "--------------------------------------------------\n",
            "Processing article 199/200: winodict_probing_language_models_for_in-context_word_acquisition\n",
            "Done in 7.72s | Avg: 20.07s | Remaining: 1 | ETA: 2025-05-09 16:22:09\n",
            "--------------------------------------------------\n",
            "Processing article 200/200: set_learning_for_generative_information_extraction\n",
            "Done in 11.97s | Avg: 20.03s | Remaining: 0 | ETA: 2025-05-09 16:22:01\n",
            "--------------------------------------------------\n",
            "All done in 67.22 minutes.\n",
            "Abstract generation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysIdLUWbjcwU",
        "outputId": "a1a52228-70cf-41b5-e73f-8e1e44931060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Baf5T1QyzI1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}