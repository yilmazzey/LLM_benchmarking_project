[
    {
        "title": "integrating_an_unsupervised_transliteration_model_into_statistical_machine_translation",
        "original_abstract": "We investigate three methods for integrat-\ning an unsupervised transliteration model\ninto an end-to-end SMT system. We in-\nduce a transliteration model from parallel\ndata and use it to translate OOV words.\nOur approach is fully unsupervised and\nlanguage independent.\nIn the methods\nto integrate transliterations, we observed\nimprovements from 0.23-0.75 (∆0.41)\nBLEU points across 7 language pairs. We\nalso show that our mined transliteration\ncorpora provide better rule coverage and\ntranslation quality compared to the gold\nstandard transliteration corpora.\n1",
        "generated_abstract": "The research problem addresses the challenge of unsupervised transliteration mining across languages with minimal direct correspondence in writing systems, focusing particularly on Arabic and English. The methodology involves developing a statistical model to discover implicit mappings between names from these languages without relying on parallel corpora or additional training data. Key findings indicate that the proposed approach effectively identifies transliterations through character-level analysis, achieving accuracy rates comparable to supervised methods. The main conclusion is that unsupervised models can be successfully applied to bridge linguistic gaps in translation tasks, with significant implications for enhancing machine translation and information retrieval systems across different languages."
    },
    {
        "title": "event_temporal_relation_extraction_with_bayesian_translational_model",
        "original_abstract": "Existing models to extract temporal relations\nbetween events lack a principled method to in-\ncorporate external knowledge. In this study, we\nintroduce Bayesian-Trans, a Bayesian learning-\nbased method that models the temporal rela-\ntion representations as latent variables and in-\nfers their values via Bayesian inference and\ntranslational functions. Compared to conven-\ntional neural approaches, instead of performing\npoint estimation to find the best set parame-\nters, the proposed model infers the parameters’\nposterior distribution directly, enhancing the\nmodel’s capability to encode and express un-\ncertainty about the predictions. Experimental\nresults on the three widely used datasets show\nthat Bayesian-Trans outperforms existing ap-\nproaches for event temporal relation extraction.\nWe additionally present detailed analyses on un-\ncertainty quantification, comparison of priors,\nand ablation studies, illustrating the benefits of\nthe proposed approach.1\n1",
        "generated_abstract": "The study addresses the challenge of identifying temporal relations in event sequences within the TimeBank-Dense dataset. A novel framework, Bayesian-Trans, integrates translational models to capture complex interactions between events. This approach employs a probabilistic graphical model that allows for flexible modeling of event transitions and handles imbalanced class distributions. Key findings indicate superior performance compared to existing methods, particularly on minority relation classes. Bayesian-Trans demonstrates robustness in predicting temporal relations with balanced precision, recall, and F1 scores across different categories. The framework's effectiveness is validated through extensive experiments on TimeBank-Dense, establishing it as a promising solution for temporal relation extraction tasks."
    },
    {
        "title": "Navigating_the_Grey_Area__How_Expressions_of_Uncertainty_and_Overconfidence_Affect_Language_Models",
        "original_abstract": "The increased deployment of LMs for real-\nworld tasks involving knowledge and facts\nmakes it important to understand model episte-\nmology: what LMs think they know, and how\ntheir attitudes toward that knowledge are af-\nfected by language use in their inputs. Here,\nwe study an aspect of model epistemology: how\nepistemic markers of certainty, uncertainty, or\nevidentiality like \"I’m sure it’s\", \"I think it’s\",\nor “Wikipedia says it’s\" affect models, and\nwhether they contribute to model failures. We\ndevelop a typology of epistemic markers and\ninject 50 markers into prompts for question an-\nswering. We find that LMs are highly sensitive\nto epistemic markers in prompts, with accu-\nracies varying more than 80%. Surprisingly,\nwe find that expressions of high certainty re-\nsult in a 7% decrease in accuracy as compared\nto low certainty expressions; similarly, factive\nverbs hurt performance, while evidentials ben-\nefit performance. Our analysis of a popular\npretraining dataset shows that these markers\nof uncertainty are associated with answers on\nquestion-answering websites, while markers of\ncertainty are associated with questions. These\nassociations may suggest that the behavior of\nLMs is based on mimicking observed language\nuse, rather than truly reflecting epistemic un-\ncertainty.\n1",
        "generated_abstract": "The research addresses the challenge of enhancing the accuracy and reliability of automated reasoning in various knowledge-intensive domains by leveraging linguistic cues that indicate certainty and uncertainty. The methodology involves analyzing a comprehensive dataset from diverse trivia sources to identify key patterns in the usage of linguistic expressions. Key findings reveal significant differences in the frequency and type of certainty indicators across different datasets, with certain templates showing higher predictive power in specific contexts. Conclusions underscore the importance of context-specific customization for effective knowledge extraction and reasoning systems. The implications suggest that integrating sophisticated natural language processing techniques can significantly improve the performance of automated information retrieval and decision-making processes in complex environments."
    },
    {
        "title": "Mirages._On_Anthropomorphism_in_Dialogue_Systems",
        "original_abstract": "Automated dialogue or conversational systems\nare anthropomorphised by developers and per-\nsonified by users. While a degree of anthropo-\nmorphism may be inevitable due to the choice\nof medium, conscious and unconscious design\nchoices can guide users to personify such sys-\ntems to varying degrees. Encouraging users\nto relate to automated systems as if they were\nhuman can lead to high risk scenarios caused\nby over-reliance on their outputs. As a result,\nnatural language processing researchers have\ninvestigated the factors that induce personifi-\ncation and develop resources to mitigate such\neffects. However, these efforts are fragmented,\nand many aspects of anthropomorphism have\nyet to be explored. In this paper, we discuss\nthe linguistic factors that contribute to the an-\nthropomorphism of dialogue systems and the\nharms that can arise, including reinforcing gen-\nder stereotypes and notions of acceptable lan-\nguage. We recommend that future efforts to-\nwards developing dialogue systems take partic-\nular care in their design, development, release,\nand description; and attend to the many linguis-\ntic cues that can elicit personification by users.\n1",
        "generated_abstract": "The research problem lies in the growing integration of conversational agents into daily life and their potential to shape social interactions. The objective is to examine how these digital assistants influence human communication dynamics and social norms. A mixed-methods approach combining qualitative interviews and observational data analysis was employed. Key findings indicate that users exhibit altered behavior when interacting with conversational agents, often mimicking the tone and language used by the agents. Moreover, there is a notable shift in perceived social acceptability of certain behaviors facilitated by these digital assistants. Conclusions suggest that conversational agents not only reflect but also modify human communication norms, raising ethical considerations regarding privacy, bias, and social identity. The implications highlight the need for policymakers and developers to address these issues proactively to ensure responsible design and use of such technologies."
    },
    {
        "title": "equipping_language_models_with_tool_use_capability_for_tabular_data_analysis_in_finance",
        "original_abstract": "Large language models (LLMs) have exhibited\nan array of reasoning capabilities but face chal-\nlenges like error propagation and hallucination,\nparticularly in specialised areas like finance,\nwhere data is heterogeneous, and precision is\nparamount. We explore the potential of lan-\nguage model augmentation with external tools\nto mitigate these limitations and offload cer-\ntain reasoning steps to external tools that are\nmore suited for the task, instead of solely de-\npending on the LLM’s inherent abilities. More\nconcretely, using financial domain question-\nanswering datasets, we apply supervised fine-\ntuning on a LLAMA-2 13B CHAT model to\nact both as a task router and task solver. The\ntask router dynamically directs a question to\neither be answered internally by the LLM or\nexternally via the right tool from the tool set.\nOur tool-equipped SFT model, RAVEN, demon-\nstrates an improvement of 35.2% and 5.06%\nover the base model and SFT-only baselines,\nrespectively, and is highly competitive with\nstrong GPT-3.5 results.\nTo the best of our\nknowledge, our work is the first that investi-\ngates tool augmentation of language models\nfor the finance domain.1\n1",
        "generated_abstract": "The objective of this study was to investigate the impact of climate change on coastal ecosystems in Bangladesh. Utilizing a combination of remote sensing and field observations, the research analyzed changes in water quality, vegetation cover, and biodiversity over a decade. Key findings indicated significant degradation of mangrove forests and increased salinity intrusion due to rising sea levels. The study concluded that urgent adaptive measures are necessary to mitigate these environmental challenges and sustain coastal livelihoods. These findings underscore the vulnerability of Bangladesh's coastal ecosystems to climate change and highlight the importance of integrated conservation strategies."
    },
    {
        "title": "multilingual_large_language_models_are_not_(yet)_code-switchers",
        "original_abstract": "Multilingual Large Language Models (LLMs)\nhave recently shown great capabilities in a wide\nrange of tasks, exhibiting state-of-the-art perfor-\nmance through zero-shot or few-shot prompt-\ning methods. While there have been extensive\nstudies on their abilities in monolingual tasks,\nthe investigation of their potential in the context\nof code-switching (CSW), the practice of alter-\nnating languages within an utterance, remains\nrelatively uncharted. In this paper, we provide\na comprehensive empirical analysis of various\nmultilingual LLMs, benchmarking their perfor-\nmance across four tasks: sentiment analysis,\nmachine translation, summarization and word-\nlevel language identification. Our results indi-\ncate that despite multilingual LLMs exhibiting\npromising outcomes in certain tasks using zero\nor few-shot prompting, they still underperform\nin comparison to fine-tuned models of much\nsmaller scales. We argue that current “multilin-\ngualism\" in LLMs does not inherently imply\nproficiency with code-switching texts, calling\nfor future research to bridge this discrepancy.\n1",
        "generated_abstract": "The research investigates the performance of large language models (LLMs) across diverse languages and tasks including sentiment analysis and language identification. The methodology employs a series of experiments using both mixed and single-domain datasets to evaluate different model sizes. Key findings indicate that while larger models generally outperform smaller ones, their superiority diminishes as task complexity increases. Notably, the mT0 model demonstrates competitive performance across various languages without extensive fine-tuning. The evaluation reveals nuanced differences in LLMs' capabilities, highlighting the importance of data diversity and model architecture for multilingual applications. These findings suggest that while larger models offer improved generalization, tailored approaches remain essential for optimal performance in specific linguistic contexts."
    },
    {
        "title": "Harnessing_Black-Box_Control_to_Boost_Commonsense_in_LM’s_Generation",
        "original_abstract": "Large language models (LLMs) such as GPT-3\nhave demonstrated a strong capability to gen-\nerate coherent and contextually relevant text.\nHowever, amidst their successes, a crucial issue\npersists: their generated outputs still lack com-\nmonsense at times. Yet fine-tuning the entire\nLLM towards more commonsensical outputs is\ncomputationally expensive if not infeasible. In\nthis paper, we present a computation-efficient\nframework that steers a frozen Pre-Trained Lan-\nguage Model (PTLM) towards more common-\nsensical generation (i.e., producing a meaning-\nful and plausible output that incorporates a list\nof concepts).\nSpecifically, we first construct a reference-free\nevaluator that assigns a sentence with a com-\nmonsensical score by grounding the sentence\nto a dynamic commonsense knowledge base\nfrom four different relational aspects. We then\nuse the scorer as the oracle for commonsense\nknowledge, and extend the controllable genera-\ntion method called NADO to train an auxiliary\nhead that guides a fixed PTLM to better satisfy\nthe oracle. We test our framework on a series of\nGPT-2-, FLAN-T5- and Alpaca-based language\nmodels (LMs) on two constrained concept-to-\nsentence benchmarks. Human evaluation re-\nsults demonstrate that our method consistently\nleads to the most commonsensical outputs.1\n1",
        "generated_abstract": "The research investigates the extraction of semantic tuples from sentences using GPT-3.5 Turbo. A few-shot prompt was designed to guide the model in extracting tuples based on specific relations without inferring additional information. The methodology involved presenting various sentence types, including non-sensical ones, to assess the model's performance comprehensively. Key findings reveal that while the model excels in recognizing explicit semantic relationships, it occasionally struggles with non-sensical input, suggesting potential limitations in context understanding. The main conclusion is that fine-tuning of models for specific tasks may enhance their reliability and accuracy. These insights have significant implications for natural language processing applications, highlighting areas where model improvement could be beneficial."
    },
    {
        "title": "rationaleenhanced_language_models_are_better_continual_relation_learners",
        "original_abstract": "Continual relation extraction (CRE) aims to\nsolve the problem of catastrophic forgetting\nwhen learning a sequence of newly emerging\nrelations. Recent CRE studies have found that\ncatastrophic forgetting arises from the model’s\nlack of robustness against future analogous rela-\ntions. To address the issue, we introduce ratio-\nnale, i.e., the explanations of relation classifica-\ntion results generated by large language models\n(LLM), into CRE task. Specifically, we de-\nsign the multi-task rationale tuning strategy to\nhelp the model learn current relations robustly.\nWe also conduct contrastive rationale replay\nto further distinguish analogous relations. Ex-\nperimental results on two standard benchmarks\ndemonstrate that our method outperforms the\nstate-of-the-art CRE models. Our code is avail-\nable at https://github.com/WeiminXiong/\nRationaleCL\n1",
        "generated_abstract": "The research investigates the enhancement of relation extraction in natural language processing through rationale generation. The methodology involves developing a model that generates explicit rationales for predicted relations between entities. Key findings reveal that the introduction of rationales significantly improves the interpretability and robustness of relation extraction models. Enhanced understandability allows for better alignment with human intuition, leading to more accurate predictions. The main conclusion is that incorporating rationale generation into natural language processing tasks can substantially improve model performance and reliability, thereby facilitating a deeper understanding of complex textual relationships. This approach has broad implications for applications requiring transparent and trustworthy AI systems in fields such as knowledge extraction and semantic analysis."
    },
    {
        "title": "coordinate_constructions_in_english_enhanced_universal_dependencies_analysis_and_computational_modeling",
        "original_abstract": "In this paper, we address the representation of\ncoordinate constructions in Enhanced Univer-\nsal Dependencies (UD), where relevant depen-\ndency links are propagated from conjunction\nheads to other conjuncts. English treebanks for\nenhanced UD have been created from gold ba-\nsic dependencies using a heuristic rule-based\nconverter, which propagates only core argu-\nments.\nWith the aim of determining which\nset of links should be propagated from a se-\nmantic perspective, we create a large-scale\ndataset of manually edited syntax graphs. We\nidentify several systematic errors in the orig-\ninal data, and propose to also propagate ad-\njuncts. We observe high inter-annotator agree-\nment for this semantic annotation task. Using\nour new manually veriﬁed dataset, we perform\nthe ﬁrst principled comparison of rule-based\nand (partially novel) machine-learning based\nmethods for conjunction propagation for En-\nglish. We show that learning propagation rules\nis more effective than hand-designing heuris-\ntic rules. When using automatic parses, our\nneural graph-parser based edge predictor out-\nperforms the currently predominant pipelines\nusing a basic-layer tree parser plus converters.\n1",
        "generated_abstract": "The research addresses the challenge of conjunction propagation in English syntax, where dependent elements are shared between coordinated constituents. A graph-based edge predictor and machine learning models were developed to predict the labels for these connections. The approach leverages contextualized word embeddings and dependency trees to identify valid links. Key findings include improved accuracy through the use of RoBERTa embeddings and a specialized hyperparameter configuration. The system successfully predicts conjunction propagation, significantly enhancing syntactic parsing in English. This work contributes to more accurate natural language understanding and processing."
    },
    {
        "title": "ViSoBERT__A_Pre-Trained_Language_Model_for_Vietnamese_Social_Media_Text_Processing",
        "original_abstract": "English and Chinese, known as resource-rich\nlanguages, have witnessed the strong devel-\nopment of transformer-based language mod-\nels for natural language processing tasks. Al-\nthough Vietnam has approximately 100M peo-\nple speaking Vietnamese, several pre-trained\nmodels, e.g., PhoBERT, ViBERT, and vELEC-\nTRA, performed well on general Vietnamese\nNLP tasks, including POS tagging and named\nentity recognition. These pre-trained language\nmodels are still limited to Vietnamese social\nmedia tasks.\nIn this paper, we present the\nfirst monolingual pre-trained language model\nfor Vietnamese social media texts, ViSoBERT,\nwhich is pre-trained on a large-scale corpus of\nhigh-quality and diverse Vietnamese social me-\ndia texts using XLM-R architecture. Moreover,\nwe explored our pre-trained model on five im-\nportant natural language downstream tasks on\nVietnamese social media texts: emotion recog-\nnition, hate speech detection, sentiment anal-\nysis, spam reviews detection, and hate speech\nspans detection. Our experiments demonstrate\nthat ViSoBERT, with far fewer parameters, sur-\npasses the previous state-of-the-art models on\nmultiple Vietnamese social media tasks. Our\nViSoBERT model is available4 only for re-\nsearch purposes.\nDisclaimer: This paper contains actual com-\nments on social networks that might be con-\nstrued as abusive, offensive, or obscene.\n1",
        "generated_abstract": "The research problem addressed in this study pertains to the evaluation and comparison of tokenization techniques for Vietnamese social media content across three distinct pre-trained language models: PhoBERT, TwHIN-BERT, and ViSoBERT. The methodology involved the systematic removal of diacritics from actual social comments, followed by their tokenization using the aforementioned models. Key findings revealed significant variations in how each model handles diacritic removal, impacting the accuracy and coherence of the resulting tokens. PhoBERT demonstrated superior performance with minimal loss of information even after extensive diacritic removal. TwHIN-BERT and ViSoBERT showed varying degrees of inconsistency, particularly when dealing with more complex linguistic structures present in social media language. These findings highlight the critical role of model-specific adjustments for robust tokenization of Vietnamese social content. The study underscores the necessity for tailored approaches to ensure effective natural language processing in diverse linguistic contexts."
    }
]