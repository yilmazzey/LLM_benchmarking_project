[
    {
        "title": "integrating_an_unsupervised_transliteration_model_into_statistical_machine_translation",
        "original_abstract": "We investigate three methods for integrat-\ning an unsupervised transliteration model\ninto an end-to-end SMT system. We in-\nduce a transliteration model from parallel\ndata and use it to translate OOV words.\nOur approach is fully unsupervised and\nlanguage independent.\nIn the methods\nto integrate transliterations, we observed\nimprovements from 0.23-0.75 (∆0.41)\nBLEU points across 7 language pairs. We\nalso show that our mined transliteration\ncorpora provide better rule coverage and\ntranslation quality compared to the gold\nstandard transliteration corpora.\n1",
        "generated_abstract": "This study investigates advanced methods for improving transliteration accuracy in statistical machine translation, particularly focusing on closely-related languages. The research explores various approaches, including supervised and unsupervised methodologies, to enhance name translation performance across different linguistic domains. By leveraging character-level and word-level models, the study presents a hybrid approach that combines these techniques to optimize transliteration accuracy. Key findings demonstrate improved precision in translating names, especially when applying both supervised and unsupervised learning strategies. The main conclusion highlights the effectiveness of this hybrid model in achieving robust and accurate name translation across multilingual settings."
    },
    {
        "title": "event_temporal_relation_extraction_with_bayesian_translational_model",
        "original_abstract": "Existing models to extract temporal relations\nbetween events lack a principled method to in-\ncorporate external knowledge. In this study, we\nintroduce Bayesian-Trans, a Bayesian learning-\nbased method that models the temporal rela-\ntion representations as latent variables and in-\nfers their values via Bayesian inference and\ntranslational functions. Compared to conven-\ntional neural approaches, instead of performing\npoint estimation to find the best set parame-\nters, the proposed model infers the parameters’\nposterior distribution directly, enhancing the\nmodel’s capability to encode and express un-\ncertainty about the predictions. Experimental\nresults on the three widely used datasets show\nthat Bayesian-Trans outperforms existing ap-\nproaches for event temporal relation extraction.\nWe additionally present detailed analyses on un-\ncertainty quantification, comparison of priors,\nand ablation studies, illustrating the benefits of\nthe proposed approach.1\n1",
        "generated_abstract": "This research explores the translation of temporal relations using a Bayesian framework and evaluates various translational models. The study focuses on predicting whether one event precedes another (before), occurs simultaneously (simultaneous), is included within another (includes), or is included in another (isincluded), or does not relate (none). The methodology involves training a model to determine the most suitable translation function for each relation type, leveraging both addition and scaling transformations. The findings reveal that the Bayesian-Trans framework, particularly using the MuRE model, achieves high precision and recall on common relations like before and after but struggles with minority classes such as equal and vague due to data scarcity. Overall, the study highlights the effectiveness of Bayesian learning for temporal relation prediction, demonstrating its potential in improving understanding of temporal dependencies in text processing tasks."
    },
    {
        "title": "Navigating_the_Grey_Area__How_Expressions_of_Uncertainty_and_Overconfidence_Affect_Language_Models",
        "original_abstract": "The increased deployment of LMs for real-\nworld tasks involving knowledge and facts\nmakes it important to understand model episte-\nmology: what LMs think they know, and how\ntheir attitudes toward that knowledge are af-\nfected by language use in their inputs. Here,\nwe study an aspect of model epistemology: how\nepistemic markers of certainty, uncertainty, or\nevidentiality like \"I’m sure it’s\", \"I think it’s\",\nor “Wikipedia says it’s\" affect models, and\nwhether they contribute to model failures. We\ndevelop a typology of epistemic markers and\ninject 50 markers into prompts for question an-\nswering. We find that LMs are highly sensitive\nto epistemic markers in prompts, with accu-\nracies varying more than 80%. Surprisingly,\nwe find that expressions of high certainty re-\nsult in a 7% decrease in accuracy as compared\nto low certainty expressions; similarly, factive\nverbs hurt performance, while evidentials ben-\nefit performance. Our analysis of a popular\npretraining dataset shows that these markers\nof uncertainty are associated with answers on\nquestion-answering websites, while markers of\ncertainty are associated with questions. These\nassociations may suggest that the behavior of\nLMs is based on mimicking observed language\nuse, rather than truly reflecting epistemic un-\ncertainty.\n1",
        "generated_abstract": "This study investigates the impact of language patterns on the perception and processing of information, focusing on expressions of certainty and uncertainty. By analyzing datasets from diverse domains, including Jeopardy, CountryQA, NaturalQA, and others, this research identifies how specific templates influence understanding and retention. The methodology employs computational linguistics techniques to categorize and quantify these linguistic patterns, revealing that certain structures significantly affect comprehension and credibility. Key findings highlight the effectiveness of certain certainty expressions in enhancing persuasion and retention, as well as the role of uncertainty in influencing source credibility. The conclusions underscore the importance of language choice in shaping information processing, offering insights for effective communication strategies across various contexts."
    },
    {
        "title": "Mirages._On_Anthropomorphism_in_Dialogue_Systems",
        "original_abstract": "Automated dialogue or conversational systems\nare anthropomorphised by developers and per-\nsonified by users. While a degree of anthropo-\nmorphism may be inevitable due to the choice\nof medium, conscious and unconscious design\nchoices can guide users to personify such sys-\ntems to varying degrees. Encouraging users\nto relate to automated systems as if they were\nhuman can lead to high risk scenarios caused\nby over-reliance on their outputs. As a result,\nnatural language processing researchers have\ninvestigated the factors that induce personifi-\ncation and develop resources to mitigate such\neffects. However, these efforts are fragmented,\nand many aspects of anthropomorphism have\nyet to be explored. In this paper, we discuss\nthe linguistic factors that contribute to the an-\nthropomorphism of dialogue systems and the\nharms that can arise, including reinforcing gen-\nder stereotypes and notions of acceptable lan-\nguage. We recommend that future efforts to-\nwards developing dialogue systems take partic-\nular care in their design, development, release,\nand description; and attend to the many linguis-\ntic cues that can elicit personification by users.\n1",
        "generated_abstract": "This study investigates the interaction between human expectations of AI voice assistants and the cultural and gendered biases inherent in their design. By synthesizing existing literature on anthropomorphism, user preferences, and ethical considerations, the research examines how users perceive gendered language in digital assistants and the extent to which developers account for cultural differences. The findings reveal that while users often expect neutral and culturally sensitive interactions, current implementations frequently fall short due to oversimplified voice representations. This highlights the need for a more nuanced approach to AI voice design, grounded in ethical principles to avoid reinforcing harmful stereotypes or biases. The results underscore the importance of developing robust guidelines to ensure that digital assistants are inclusive, respectful, and responsive to diverse user needs."
    },
    {
        "title": "equipping_language_models_with_tool_use_capability_for_tabular_data_analysis_in_finance",
        "original_abstract": "Large language models (LLMs) have exhibited\nan array of reasoning capabilities but face chal-\nlenges like error propagation and hallucination,\nparticularly in specialised areas like finance,\nwhere data is heterogeneous, and precision is\nparamount. We explore the potential of lan-\nguage model augmentation with external tools\nto mitigate these limitations and offload cer-\ntain reasoning steps to external tools that are\nmore suited for the task, instead of solely de-\npending on the LLM’s inherent abilities. More\nconcretely, using financial domain question-\nanswering datasets, we apply supervised fine-\ntuning on a LLAMA-2 13B CHAT model to\nact both as a task router and task solver. The\ntask router dynamically directs a question to\neither be answered internally by the LLM or\nexternally via the right tool from the tool set.\nOur tool-equipped SFT model, RAVEN, demon-\nstrates an improvement of 35.2% and 5.06%\nover the base model and SFT-only baselines,\nrespectively, and is highly competitive with\nstrong GPT-3.5 results.\nTo the best of our\nknowledge, our work is the first that investi-\ngates tool augmentation of language models\nfor the finance domain.1\n1",
        "generated_abstract": "The research examined changes in gains recognized in other comprehensive income (OCI), net of tax, from $1 million, $11 million, and $4 million between 2018 and 2019. The study analyzed financial reports to assess these changes' impact on financial stability and stakeholder decisions. Key findings indicated a notable increase in OCI gains, which may have influenced earnings, though their effect on net income was tempered by tax effects. Conclusions highlighted that these changes could be material for stakeholders evaluating financial health, suggesting ongoing monitoring is essential. The implications underscore the need for comprehensive analysis to understand financial trends and their broader impacts."
    },
    {
        "title": "multilingual_large_language_models_are_not_(yet)_code-switchers",
        "original_abstract": "Multilingual Large Language Models (LLMs)\nhave recently shown great capabilities in a wide\nrange of tasks, exhibiting state-of-the-art perfor-\nmance through zero-shot or few-shot prompt-\ning methods. While there have been extensive\nstudies on their abilities in monolingual tasks,\nthe investigation of their potential in the context\nof code-switching (CSW), the practice of alter-\nnating languages within an utterance, remains\nrelatively uncharted. In this paper, we provide\na comprehensive empirical analysis of various\nmultilingual LLMs, benchmarking their perfor-\nmance across four tasks: sentiment analysis,\nmachine translation, summarization and word-\nlevel language identification. Our results indi-\ncate that despite multilingual LLMs exhibiting\npromising outcomes in certain tasks using zero\nor few-shot prompting, they still underperform\nin comparison to fine-tuned models of much\nsmaller scales. We argue that current “multilin-\ngualism\" in LLMs does not inherently imply\nproficiency with code-switching texts, calling\nfor future research to bridge this discrepancy.\n1",
        "generated_abstract": "This research investigates the performance of multilingual language models in handling code-switching tasks across various languages, including English, Hindi, Malayalam, Tamil, Spanish, and Modern Standard Arabic. The study evaluates these models' ability to perform sentiment analysis, summarization, and word-level language identification (LID) in multilingual settings. A comprehensive methodology is employed, leveraging different model architectures such as mBERT, XLMR, BLOOMZ, and XGLM, to assess their performance across diverse language pairs. The key findings reveal that larger model sizes consistently demonstrate superior performance, while fine-tuned models exhibit enhanced accuracy for specific language tasks. The results highlight the potential of multilingual models in handling code-switching scenarios but also underscore the need for further optimization to address task-specific limitations and language pair complexities. This work provides valuable insights into the capabilities and challenges of leveraging multilingual models for cross-lingual applications."
    },
    {
        "title": "Harnessing_Black-Box_Control_to_Boost_Commonsense_in_LM’s_Generation",
        "original_abstract": "Large language models (LLMs) such as GPT-3\nhave demonstrated a strong capability to gen-\nerate coherent and contextually relevant text.\nHowever, amidst their successes, a crucial issue\npersists: their generated outputs still lack com-\nmonsense at times. Yet fine-tuning the entire\nLLM towards more commonsensical outputs is\ncomputationally expensive if not infeasible. In\nthis paper, we present a computation-efficient\nframework that steers a frozen Pre-Trained Lan-\nguage Model (PTLM) towards more common-\nsensical generation (i.e., producing a meaning-\nful and plausible output that incorporates a list\nof concepts).\nSpecifically, we first construct a reference-free\nevaluator that assigns a sentence with a com-\nmonsensical score by grounding the sentence\nto a dynamic commonsense knowledge base\nfrom four different relational aspects. We then\nuse the scorer as the oracle for commonsense\nknowledge, and extend the controllable genera-\ntion method called NADO to train an auxiliary\nhead that guides a fixed PTLM to better satisfy\nthe oracle. We test our framework on a series of\nGPT-2-, FLAN-T5- and Alpaca-based language\nmodels (LMs) on two constrained concept-to-\nsentence benchmarks. Human evaluation re-\nsults demonstrate that our method consistently\nleads to the most commonsensical outputs.1\n1",
        "generated_abstract": "This study investigates the automated extraction of specific relational tuples (A, B) from sentences based on predefined categories: IsUsedFor, AtLocation, CapableOf, and PartOf. The research employs a few-shot prompt approach using GPT-3.5-turbo to guide the model in identifying and extracting these relations without inferencing beyond what is explicitly mentioned in the text. The methodology leverages structured instructions to ensure accuracy while minimizing ambiguity. Experimental results demonstrate that the model successfully identifies relevant tuples across diverse domains, though performance varies slightly with non-sensical or ambiguous phrasing. These findings contribute to advancements in natural language processing by providing a novel framework for semi-supervised tuple extraction. The conclusions highlight the potential of few-shot prompting as an effective tool for structured information retrieval, while also identifying limitations that warrant further exploration."
    },
    {
        "title": "rationaleenhanced_language_models_are_better_continual_relation_learners",
        "original_abstract": "Continual relation extraction (CRE) aims to\nsolve the problem of catastrophic forgetting\nwhen learning a sequence of newly emerging\nrelations. Recent CRE studies have found that\ncatastrophic forgetting arises from the model’s\nlack of robustness against future analogous rela-\ntions. To address the issue, we introduce ratio-\nnale, i.e., the explanations of relation classifica-\ntion results generated by large language models\n(LLM), into CRE task. Specifically, we de-\nsign the multi-task rationale tuning strategy to\nhelp the model learn current relations robustly.\nWe also conduct contrastive rationale replay\nto further distinguish analogous relations. Ex-\nperimental results on two standard benchmarks\ndemonstrate that our method outperforms the\nstate-of-the-art CRE models. Our code is avail-\nable at https://github.com/WeiminXiong/\nRationaleCL\n1",
        "generated_abstract": "This research introduces RationaleCL, a novel model designed to generate structured and contextually rich rationales for entity relation identification. Addressing the challenge of providing clear explanations in entity linking tasks, RationaleCL is trained on labeled datasets and evaluated through both in-domain and cross-domain tests. Results demonstrate its ability to effectively articulate reasoning behind relation assignments, significantly outperforming existing methods like S-BERT and TextGrapher. The model excels in highlighting analogous relations and avoiding spurious connections, providing a deeper understanding of context-driven relations. This advancement enhances interpretability in applications such as educational tools and complex NLP tasks, offering valuable insights for users seeking clearer explanations. RationaleCL thus represents a meaningful contribution to enhancing reasoning transparency and accessibility."
    },
    {
        "title": "coordinate_constructions_in_english_enhanced_universal_dependencies_analysis_and_computational_modeling",
        "original_abstract": "In this paper, we address the representation of\ncoordinate constructions in Enhanced Univer-\nsal Dependencies (UD), where relevant depen-\ndency links are propagated from conjunction\nheads to other conjuncts. English treebanks for\nenhanced UD have been created from gold ba-\nsic dependencies using a heuristic rule-based\nconverter, which propagates only core argu-\nments.\nWith the aim of determining which\nset of links should be propagated from a se-\nmantic perspective, we create a large-scale\ndataset of manually edited syntax graphs. We\nidentify several systematic errors in the orig-\ninal data, and propose to also propagate ad-\njuncts. We observe high inter-annotator agree-\nment for this semantic annotation task. Using\nour new manually veriﬁed dataset, we perform\nthe ﬁrst principled comparison of rule-based\nand (partially novel) machine-learning based\nmethods for conjunction propagation for En-\nglish. We show that learning propagation rules\nis more effective than hand-designing heuris-\ntic rules. When using automatic parses, our\nneural graph-parser based edge predictor out-\nperforms the currently predominant pipelines\nusing a basic-layer tree parser plus converters.\n1",
        "generated_abstract": "This study investigates the enhancement of the Enhanced Walliser Treebank (EWT) by focusing on conjunction propagation in dependency graphs. We propose a machine learning-based approach using SVM and NN models to automate the labor-intensive process of propagating dependencies from conjunction heads to their dependents. The methodology involves creating new annotation features, such as contextualized word embeddings and linear dependency directions, based on the properties of conjunctions and their propagation targets. We leverage RoBERTa embeddings and develop a graph-based edge predictor that utilizes lexicalization rules and conjunction head information to infer missing dependencies. Our experiments demonstrate improved accuracy in automatically propagating dependencies compared to manual annotations. The results suggest that both SVM and NN models achieve high performance, with slight variations dependent on specific hyperparameters. This work enhances the EWT's structural annotation capabilities, providing valuable resources for linguistic research into multi-word phenomena. The findings underscore the potential of machine learning and graph-based approaches in streamlining dependency resolution tasks, reducing dependency on manual annotations."
    },
    {
        "title": "ViSoBERT__A_Pre-Trained_Language_Model_for_Vietnamese_Social_Media_Text_Processing",
        "original_abstract": "English and Chinese, known as resource-rich\nlanguages, have witnessed the strong devel-\nopment of transformer-based language mod-\nels for natural language processing tasks. Al-\nthough Vietnam has approximately 100M peo-\nple speaking Vietnamese, several pre-trained\nmodels, e.g., PhoBERT, ViBERT, and vELEC-\nTRA, performed well on general Vietnamese\nNLP tasks, including POS tagging and named\nentity recognition. These pre-trained language\nmodels are still limited to Vietnamese social\nmedia tasks.\nIn this paper, we present the\nfirst monolingual pre-trained language model\nfor Vietnamese social media texts, ViSoBERT,\nwhich is pre-trained on a large-scale corpus of\nhigh-quality and diverse Vietnamese social me-\ndia texts using XLM-R architecture. Moreover,\nwe explored our pre-trained model on five im-\nportant natural language downstream tasks on\nVietnamese social media texts: emotion recog-\nnition, hate speech detection, sentiment anal-\nysis, spam reviews detection, and hate speech\nspans detection. Our experiments demonstrate\nthat ViSoBERT, with far fewer parameters, sur-\npasses the previous state-of-the-art models on\nmultiple Vietnamese social media tasks. Our\nViSoBERT model is available4 only for re-\nsearch purposes.\nDisclaimer: This paper contains actual com-\nments on social networks that might be con-\nstrued as abusive, offensive, or obscene.\n1",
        "generated_abstract": "This study investigates the impact of diacritic removal on the tokenization of potentially offensive social comments by Vietnamese neural language models: PhoBERT, TwHIN-BERT, and ViSoBERT. The research examines how different levels of diacritic removal (100%, 75%, and 25%) affect the tokenization accuracy and the perceived harmfulness of such comments. By comparing the performance of these models across varying diacritic removal levels, the findings reveal that more aggressive removal tends to improve content safety but may inadvertently lead to problematic word splits. The results also highlight that model architecture significantly influences tokenization outcomes. These insights suggest that while diacritic removal can enhance social media safety, its implementation must be meticulously managed to avoid mis-tokenization and unintended content alterations. The findings offer valuable guidance for platform developers aiming to balance user safety with the integrity of content interpretation."
    }
]