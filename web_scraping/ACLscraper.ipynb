{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC #expilicit wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.http import MediaIoBaseUpload\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Drive Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authenticate with Google Drive API\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Google Drive\n",
    "def authenticate_google_drive():\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    drive_service = build('drive', 'v3', credentials=creds)\n",
    "    return drive_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_service = authenticate_google_drive()\n",
    "parent_folder_id = '1WZ2l6ZT3Op4X7P95wrLt2P2asVxd6rMz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium Konfigürasyonları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hızlı olsun diye, js link veya butonu çıkarsa js engelini kaldır\n",
    "options = Options()\n",
    "prefs = {\"profile.default_content_setting_values\": {\"images\": 2, \"javascript\": 2}}  # Block images and JS\n",
    "options.headless = True # Run in headless mode\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://aclanthology.org\")\n",
    "driver.implicitly_wait(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the table containing the event links\n",
    "try:\n",
    "    table = driver.find_element(By.XPATH, \"//h6[text()='ACL Events']/following-sibling::table[contains(@class, 'table-hover')]\")\n",
    "    print(\"ACL Events table found successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: Table not found. {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google drive main operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a folder already exists in Google Drive\n",
    "def check_folder_exists(service, folder_name, parent_folder_id=None):\n",
    "    query = f\"name='{folder_name}' and mimeType='application/vnd.google-apps.folder'\"\n",
    "    if parent_folder_id:\n",
    "        query += f\" and '{parent_folder_id}' in parents\"\n",
    "    \n",
    "    results = service.files().list(q=query, spaces='drive').execute()\n",
    "    files = results.get('files', [])\n",
    "    if files:\n",
    "        return files[0]['id']  # Return the existing folder ID\n",
    "    return None\n",
    "\n",
    "# Function to create a folder in Google Drive\n",
    "def create_folder_in_drive(service, folder_name, parent_folder_id=None):\n",
    "    folder_metadata = {\n",
    "        'name': folder_name,\n",
    "        'mimeType': 'application/vnd.google-apps.folder',\n",
    "    }\n",
    "    if parent_folder_id:\n",
    "        folder_metadata['parents'] = [parent_folder_id]\n",
    "    folder = service.files().create(body=folder_metadata, fields='id').execute()\n",
    "    print(f\"Folder '{folder_name}' created with ID: {folder.get('id')}\")\n",
    "    return folder.get('id')\n",
    "\n",
    "# Function to upload a file to Google Drive\n",
    "def upload_file_to_drive(service, file_name, folder_id, file_content):\n",
    "    file_metadata = {\n",
    "        'name': file_name,\n",
    "        'parents': [folder_id]\n",
    "    }\n",
    "    media = MediaIoBaseUpload(io.BytesIO(file_content), mimetype='application/pdf')\n",
    "    \n",
    "    # Upload the file to Google Drive\n",
    "    uploaded_file = service.files().create(\n",
    "        body=file_metadata,\n",
    "        media_body=media,\n",
    "        fields='id'\n",
    "    ).execute()\n",
    "\n",
    "    print(f\"Uploaded {file_name} to Google Drive with ID: {uploaded_file.get('id')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint_from_drive(service, folder_id):\n",
    "    # Query for the checkpoint file in the given volume folder\n",
    "    query = f\"name='checkpoint.txt' and '{folder_id}' in parents\"\n",
    "    results = service.files().list(q=query, spaces='drive').execute()\n",
    "    files = results.get('files', [])\n",
    "    \n",
    "    if files:\n",
    "        checkpoint_file_id = files[0]['id']\n",
    "        checkpoint_content = service.files().get_media(fileId=checkpoint_file_id).execute().decode('utf-8')\n",
    "        processed_papers = set(checkpoint_content.split('\\n'))\n",
    "        print(f\"Loaded {len(processed_papers)} processed papers from checkpoint.\")\n",
    "    else:\n",
    "        processed_papers = set()\n",
    "        print(\"No checkpoint file found. Starting fresh.\")\n",
    "    \n",
    "    return processed_papers\n",
    "\n",
    "# Function to update the checkpoint.txt file in Google Drive\n",
    "def update_checkpoint_in_drive(service, folder_id, paper_title):\n",
    "    # Query for the checkpoint file\n",
    "    query = f\"name='checkpoint.txt' and '{folder_id}' in parents\"\n",
    "    results = service.files().list(q=query, spaces='drive').execute()\n",
    "    files = results.get('files', [])\n",
    "    \n",
    "    if files:\n",
    "        checkpoint_file_id = files[0]['id']\n",
    "        # Get the existing content\n",
    "        existing_content = service.files().get_media(fileId=checkpoint_file_id).execute().decode('utf-8')\n",
    "        new_content = existing_content + paper_title + \"\\n\"\n",
    "        media = MediaIoBaseUpload(io.BytesIO(new_content.encode('utf-8')), mimetype='text/plain')\n",
    "        service.files().update(fileId=checkpoint_file_id, media_body=media).execute()\n",
    "    else:\n",
    "        # Create a new checkpoint file if it doesn't exist\n",
    "        file_metadata = {\n",
    "            'name': 'checkpoint.txt',\n",
    "            'parents': [folder_id],\n",
    "            'mimeType': 'text/plain'\n",
    "        }\n",
    "        media = MediaIoBaseUpload(io.BytesIO((paper_title + \"\\n\").encode('utf-8')), mimetype='text/plain')\n",
    "        service.files().create(body=file_metadata, media_body=media).execute()\n",
    "    \n",
    "    print(f\"Updated checkpoint with {paper_title}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and upload the actual PDF from the paper page\n",
    "def download_and_upload_paper_pdf(driver, drive_service, volume_folder_id, paper_title, processed_papers):\n",
    "    if paper_title in processed_papers:\n",
    "        print(f\"Skipping already processed paper: {paper_title}\")\n",
    "        return  # Skip this paper if it is already processed\n",
    "\n",
    "    try:\n",
    "        # Locate the PDF link inside the paper details page\n",
    "        pdf_link = driver.find_element(By.XPATH, \"//a[@class='btn btn-primary' and contains(@href, '.pdf')]\")\n",
    "        pdf_url = pdf_link.get_attribute(\"href\")\n",
    "        paper_file_name = paper_title + \".pdf\"\n",
    "\n",
    "        # Download the PDF file\n",
    "        response = requests.get(pdf_url)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Downloaded paper: {paper_file_name}\")\n",
    "            # Upload the downloaded PDF to Google Drive\n",
    "            upload_file_to_drive(drive_service, paper_file_name, volume_folder_id, response.content)\n",
    "            # Update the checkpoint after successful upload\n",
    "            update_checkpoint_in_drive(drive_service, volume_folder_id, paper_title)\n",
    "        else:\n",
    "            print(f\"Failed to download paper PDF: {pdf_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not find PDF link on paper page. {e}\")\n",
    "\n",
    "\n",
    "def navigate_and_download_papers_from_volume(driver, drive_service, volume_folder_id):\n",
    "    # Load the checkpoint for this volume from Google Drive\n",
    "    processed_papers = load_checkpoint_from_drive(drive_service, volume_folder_id)\n",
    "\n",
    "    # Function to normalize paper titles (removes special characters, extra spaces, etc.)\n",
    "    def normalize_title(title):\n",
    "        return title.strip().replace(\" \", \"_\").replace(\":\", \"\").replace(\",\", \"\").lower()\n",
    "\n",
    "    # Normalize all the processed paper titles in the checkpoint\n",
    "    processed_papers_normalized = set([normalize_title(paper) for paper in processed_papers])\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Get all the paper links in the volume (e.g., /2023.ijcnlp-main.1)\n",
    "            paper_links = driver.find_elements(By.XPATH, \"//a[@class='align-middle' and contains(@href, '/')]\")\n",
    "            total_papers = len(paper_links)\n",
    "            processed_count = len(processed_papers_normalized)\n",
    "            print(f\"Total papers in volume: {total_papers}\")\n",
    "            print(f\"Processed papers in checkpoint: {processed_count}\")\n",
    "\n",
    "            # **Stop Condition**: If all papers are processed, exit this volume\n",
    "            if processed_count >= total_papers:\n",
    "                print(f\"All papers in volume '{volume_folder_id}' are already processed. Skipping volume.\")\n",
    "                break  # Move to the next volume\n",
    "            \n",
    "            for paper_index in range(len(paper_links)):\n",
    "                try:\n",
    "                    # Re-fetch the paper links to avoid stale element issues\n",
    "                    paper_links = driver.find_elements(By.XPATH, \"//a[@class='align-middle' and contains(@href, '/')]\")\n",
    "                    \n",
    "                    paper_link = paper_links[paper_index]\n",
    "                    paper_href = paper_link.get_attribute('href')\n",
    "                    paper_title = paper_link.text\n",
    "\n",
    "                    # Normalize the title for comparison with the checkpoint\n",
    "                    normalized_title = normalize_title(paper_title)\n",
    "\n",
    "                    # Check if the normalized title is already processed\n",
    "                    if normalized_title in processed_papers_normalized:\n",
    "                        print(f\"Skipping already processed paper: {paper_title} (Normalized: {normalized_title})\")\n",
    "                        continue  # Skip already processed papers\n",
    "\n",
    "                    print(f\"Navigating to paper: {paper_href}\")\n",
    "                    driver.get(paper_href)\n",
    "                    time.sleep(2)  # Wait for the paper details page to load\n",
    "\n",
    "                    # Try to locate the PDF download link, handle stale elements\n",
    "                    try:\n",
    "                        # Locate the PDF link inside the paper details page\n",
    "                        pdf_link = WebDriverWait(driver, 10).until(\n",
    "                            EC.presence_of_element_located((By.XPATH, \"//a[@class='btn btn-primary' and contains(@href, '.pdf')]\"))\n",
    "                        )\n",
    "                        pdf_url = pdf_link.get_attribute(\"href\")\n",
    "                        paper_file_name = normalize_title(paper_title) + \".pdf\"\n",
    "\n",
    "                        # Download the PDF file\n",
    "                        response = requests.get(pdf_url)\n",
    "                        if response.status_code == 200:\n",
    "                            print(f\"Downloaded paper: {paper_file_name}\")\n",
    "                            # Upload the downloaded PDF to Google Drive\n",
    "                            upload_file_to_drive(drive_service, paper_file_name, volume_folder_id, response.content)\n",
    "                            \n",
    "                            # Update the checkpoint after successful upload with the normalized title\n",
    "                            update_checkpoint_in_drive(drive_service, volume_folder_id, normalized_title)\n",
    "                            \n",
    "                            # **IMPORTANT**: Update the in-memory processed set\n",
    "                            processed_papers_normalized.add(normalized_title)\n",
    "\n",
    "                        else:\n",
    "                            print(f\"Failed to download paper PDF: {pdf_url}\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error: Could not find PDF link on paper page. {e}\")\n",
    "\n",
    "                    # Go back to the volume page after processing the paper\n",
    "                    driver.back()\n",
    "                    time.sleep(2)  # Wait for the volume page to reload\n",
    "\n",
    "                except StaleElementReferenceException as stale_e:\n",
    "                    print(f\"Stale element encountered while navigating paper links: {stale_e}. Refetching paper links and retrying...\")\n",
    "                    continue  # Retry the current set of paper links after refetching\n",
    "\n",
    "        except StaleElementReferenceException as stale_e:\n",
    "            print(f\"Stale element encountered while navigating volume: {stale_e}. Refetching volume and retrying...\")\n",
    "            continue  # Retry fetching the volume links if stale elements are encountered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle downloading papers from all volumes in an event\n",
    "def download_papers_from_volumes(event_folder_id, driver, drive_service):\n",
    "    # Try fetching volume links\n",
    "    while True:\n",
    "        try:\n",
    "            # Find all the volume links on the event page\n",
    "            volume_links = driver.find_elements(By.XPATH, \"//a[contains(@href, '/volumes/')]\")\n",
    "            print(f\"Found {len(volume_links)} volumes.\")\n",
    "            \n",
    "            for volume_index in range(len(volume_links)):\n",
    "                try:\n",
    "                    # Re-fetch the volume links to avoid stale element issues\n",
    "                    volume_links = driver.find_elements(By.XPATH, \"//a[contains(@href, '/volumes/')]\")\n",
    "                    \n",
    "                    # Get the volume link and its details\n",
    "                    volume_link = volume_links[volume_index]\n",
    "                    volume_href = volume_link.get_attribute('href')\n",
    "                    volume_name = volume_href.split('/')[-2]  # Extract the volume name\n",
    "                    \n",
    "                    if volume_name == \"2024.eacl-long\":\n",
    "                        print(f\"Skipping volume: {volume_name}\")\n",
    "                        continue  \n",
    "                    \n",
    "                    print(f\"Navigating to volume: {volume_name}\")\n",
    "\n",
    "                    # Navigate to the volume link\n",
    "                    driver.get(volume_href)\n",
    "                    time.sleep(2)  # Wait for the volume page to load\n",
    "\n",
    "                    # Check if a folder for this volume already exists in Google Drive\n",
    "                    volume_folder_id = check_folder_exists(drive_service, volume_name, event_folder_id)\n",
    "                    if not volume_folder_id:\n",
    "                        # If the folder doesn't exist, create it\n",
    "                        volume_folder_id = create_folder_in_drive(drive_service, volume_name, event_folder_id)\n",
    "\n",
    "                    # Navigate to each paper in the volume and download PDFs\n",
    "                    navigate_and_download_papers_from_volume(driver, drive_service, volume_folder_id)\n",
    "\n",
    "                    # Go back to the event page after processing the volume\n",
    "                    driver.back()\n",
    "                    time.sleep(2)  # Wait for the event page to reload\n",
    "\n",
    "                except StaleElementReferenceException as stale_e:\n",
    "                    print(f\"Stale element encountered: {stale_e}. Refetching volume links and retrying...\")\n",
    "                    # Retry the current volume after refetching the elements\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing volume: {e}\")\n",
    "                    continue\n",
    "\n",
    "            break  # Exit the loop when all volumes are processed\n",
    "        except StaleElementReferenceException as stale_e:\n",
    "            print(f\"Stale element encountered while fetching volumes: {stale_e}. Refetching volume links and retrying...\")\n",
    "            continue  # Retry fetching the volume links if stale elements are encountered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to traverse through all events and download papers\n",
    "def traverse_events_and_download_papers(driver, drive_service, parent_folder_id):\n",
    "    try:\n",
    "        # Locate the ACL Events table\n",
    "        table = driver.find_element(By.XPATH, \"//h6[text()='ACL Events']/following-sibling::table[contains(@class, 'table-hover')]\")\n",
    "        print(\"ACL Events table found successfully!\")\n",
    "\n",
    "        # Get all the event links using the corrected XPath\n",
    "        while True:\n",
    "            try:\n",
    "                event_links = driver.find_elements(By.XPATH, \"//th/a[contains(@href, '/venues/')]\")\n",
    "                \n",
    "                for event_index in range(len(event_links)):\n",
    "                    try:\n",
    "                        # Re-fetch the event links to avoid stale element issues\n",
    "                        event_links = driver.find_elements(By.XPATH, \"//th/a[contains(@href, '/venues/')]\")\n",
    "                        \n",
    "                        link = event_links[event_index]\n",
    "                        href = link.get_attribute(\"href\")\n",
    "                        event_name = href.split(\"/\")[-2]  # Extract the event name (e.g., \"acl\", \"conll\", \"aacl\")\n",
    "\n",
    "                        # **Skip the \"aacl\" event manually**\n",
    "                        if event_name in [\"aacl\", \"acl\",\"anlp\",\"cl\",\"findings\",\"conll\"]:\n",
    "                            print(f\"Skipping event: {event_name}\")\n",
    "                            continue  # Skip processing for the \"aacl\" event\n",
    "\n",
    "                        print(f\"Processing event: {event_name}\")\n",
    "\n",
    "                        # Navigate to the event link\n",
    "                        driver.get(href)\n",
    "                        time.sleep(2)  # Wait for the event page to load\n",
    "\n",
    "                        # Create a folder for this event in Google Drive if it doesn't exist\n",
    "                        event_folder_id = check_folder_exists(drive_service, event_name, parent_folder_id)\n",
    "                        if not event_folder_id:\n",
    "                            event_folder_id = create_folder_in_drive(drive_service, event_name, parent_folder_id)\n",
    "\n",
    "                        # Traverse volumes and download papers within the event\n",
    "                        download_papers_from_volumes(event_folder_id, driver, drive_service)\n",
    "\n",
    "                        # Go back to the main event table page after processing the event\n",
    "                        driver.back()\n",
    "                        time.sleep(2)  # Wait for the event page to reload\n",
    "\n",
    "                    except StaleElementReferenceException as stale_e:\n",
    "                        print(f\"Stale element encountered: {stale_e}. Refetching event links and retrying...\")\n",
    "                        continue  # Retry the current event after refetching the elements\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing event: {e}\")\n",
    "                        continue\n",
    "\n",
    "                break  # Exit the loop when all events are processed\n",
    "\n",
    "            except StaleElementReferenceException as stale_e:\n",
    "                print(f\"Stale element encountered while fetching events: {stale_e}. Refetching event links and retrying...\")\n",
    "                continue  # Retry fetching the event links if stale elements are encountered\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Table not found. {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traverse_events_and_download_papers(driver, drive_service, parent_folder_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
