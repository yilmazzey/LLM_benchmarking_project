[
    {
      "title": "integrating_an_unsupervised_transliteration_model_into_statistical_machine_translation",
      "abstract": "We investigate three methods for integrat-\ning an unsupervised transliteration model\ninto an end-to-end SMT system. We in-\nduce a transliteration model from parallel\ndata and use it to translate OOV words.\nOur approach is fully unsupervised and\nlanguage independent.\nIn the methods\nto integrate transliterations, we observed\nimprovements from 0.23-0.75 (∆0.41)\nBLEU points across 7 language pairs. We\nalso show that our mined transliteration\ncorpora provide better rule coverage and\ntranslation quality compared to the gold\nstandard transliteration corpora.\n1",
      "content": "All machine translation (MT) systems suffer from\nthe existence of out-of-vocabulary (OOV) words,\nirrespective of the amount of data available for\ntraining. OOV words are mostly named entities,\ntechnical terms or foreign words that can be trans-\nlated to the target language using transliteration.\nMuch work\n(Al-Onaizan and Knight, 2002;\nZhao et al., 2007; Kashani et al., 2007; Habash,\n2009) has been done on transliterating named enti-\nties and OOVs, and transliteration has been shown\nto improve MT quality. Transliteration has also\nshown to be useful for translating closely related\nlanguage pairs (Durrani et al., 2010; Nakov and\nTiedemann, 2012), and for disambiguation (Her-\nmjakob et al., 2008; Azab et al., 2013).\nHow-\never, despite its utility, a transliteration module\ndoes not exist in the commonly used MT toolk-\nits, such as Moses (Koehn et al., 2007). One of the\nmain reasons is that the training data, a corpus of\ntransliteration pairs, required to build a translitera-\ntion system, is not readily available for many lan-\nguage pairs. Even if such a training data is avail-\nable, mechanisms to integrate transliterated words\ninto MT pipelines are unavailable in these toolkits.\nGenerally, a supervised transliteration system is\ntrained separately outside of an MT pipeline, and\na na¨ıve approach, to replace OOV words with their\n1-best transliterations in the post/pre-processing\nstep of decoding is commonly used.\nIn this work i) we use an unsupervised model\nbased on Expectation Maximization (EM) to in-\nduce transliteration corpus from word aligned par-\nallel data, which is then used to train a translitera-\ntion model, ii) we investigate three different meth-\nods for integrating transliteration during decoding,\nthat we implemented within the Moses toolkit. To\nthe best of our knowledge, our work is the fore-\nmost attempt to integrate unsupervised translitera-\ntion model into SMT.\nThis paper is organized as follows. Section 2\ndescribes the unsupervised transliteration mining\nsystem, which automatically mines transliteration\npairs from the same word-aligned parallel corpus\nas used for training the MT system. Section 3 de-\nscribes the transliteration model that is trained us-\ning the automatically extracted pairs. Section 4\npresents three methods for incorporating translit-\neration into the MT pipeline, namely: i) replac-\ning OOVs with the 1-best transliteration in a post-\ndecoding step, ii) selecting the best translitera-\ntion from the list of n-best transliterations using\ntransliteration and language model features in a\npost-decoding step, iii) providing a transliteration\nphrase-table to the decoder on the ﬂy where it\ncan consider all features to select the best translit-\neration of OOV words.\nSection 5 presents re-\nsults. Our integrations achieved an average im-\nprovement of 0.41 BLEU points over a competi-\ntive baseline across 7 language pairs (Arabic, Ben-\ngali, Farsi, Hindi, Russian, Telugu and Urdu-into-\nEnglish). An additional experiment showed that\nour system provides better rule coverage as op-\nposed to another built from gold standard translit-\neration corpus and produces better translations.\n148\n\n\n2\nTransliteration Mining\nThe main bottleneck in building a transliteration\nsystem is the lack of availability of translitera-\ntion training pairs. It is, however, fair to assume\nthat any parallel data would contain a reasonable\nnumber of transliterated word pairs.\nTransliter-\nation mining can be used to extract such word\npairs from the parallel corpus.\nMost previous\ntechniques on transliteration mining generally use\nsupervised and semi-supervised methods (Sherif\nand Kondrak, 2007; Jiampojamarn et al., 2010;\nDarwish, 2010; Kahki et al., 2012).\nThis con-\nstrains the mining solution to language pairs for\nwhich training data (seed data) is available. A few\nresearchers proposed unsupervised approaches to\nmine transliterations (Lee and Choi, 1998; Sajjad\net al., 2011; Lin et al., 2011). We adapted the work\nof Sajjad et al. (2012) as summarized below.\nModel:\nThe transliteration mining model is a\nmixture of two sub-models, namely: a translit-\neration and a non-transliteration sub-model. The\nidea is that the transliteration model would as-\nsign higher probabilities to transliteration pairs\ncompared to the probabilities assigned by a non-\ntransliteration model to the same pairs. Consider a\nword pair (e, f), the transliteration model prob-\nability for the word pair is deﬁned as follows:\nptr(e, f) =\nX\na∈Align(e,f)\n|a|\nY\nj=1\np(qj)\nwhere Align(e, f) is the set of all possible se-\nquences of character alignments, a is one align-\nment sequence and qj is a character alignment.\nThe non-transliteration model deals with the\nword pairs that have no character relationship be-\ntween them. It is modeled by multiplying source\nand target character unigram models:\npntr(e, f) =\n|e|\nY\ni=1\npE(ei)\n|f|\nY\ni=1\npF (fi)\nThe transliteration mining model is deﬁned\nas an interpolation of the transliteration sub-model\nand the non-transliteration sub-model:\np(e, f) = (1 −λ)ptr(e, f) + λpntr(e, f)\nλ is the prior probability of non-transliteration.\nThe non-transliteration model does not change\nduring training. We compute it in a pre-processing\nstep.\nThe transliteration model learns character\nalignment using expectation maximization (EM).\nSee Sajjad et al. (2012) for more details.\n3\nTransliteration Model\nNow that we have transliteration word pairs, we\ncan learn a transliteration model. We segment the\ntraining corpus into characters and learn a phrase-\nbased system over character pairs. The translitera-\ntion model assumes that source and target charac-\nters are generated monotonically.1 Therefore we\ndo not use any reordering models. We use 4 basic\nphrase-translation features (direct, inverse phrase-\ntranslation, and lexical weighting features), lan-\nguage model feature (built from the target-side of\nmined transliteration corpus), and word and phrase\npenalties. The feature weights are tuned2 on a dev-\nset of 1000 transliteration pairs.\n4\nIntegration to Machine Translation\nWe experimented with three methods for integrat-\ning transliterations, described below:\nMethod 1:\ninvolves replacing OOVs in the out-\nput with the 1-best transliteration. The success of\nMethod 1 is solely contingent on the accuracy of\nthe transliteration model.\nAlso, it ignores con-\ntext which may lead to incorrect transliteration.\nFor example, the Arabic word\ntransliterates\nto “Bill” when followed by “Clinton” and “Bell”\nif preceded by “Alexander Graham”.\nMethod 2:\nprovides n-best transliterations to\na monotonic decoder that uses a monolingual\nlanguage model and a transliteration phrase-\ntranslation table to rescore transliterations.\nWe\ncarry forward the 4 translation model features used\nin the transliteration system to build a transliter-\nation phrase-table. We additionally use an LM-\nOOV feature which counts the number of words\nin a hypothesis that are unknown to the lan-\nguage model. Smoothing methods such as Kneser-\nNey assign signiﬁcant probability mass to unseen\nevents, which may cause the decoder to make in-\ncorrect transliteration selection.\nThe LM-OOV\nfeature acts as a prior to penalize such hypotheses.\nMethod 3:\nMethod 2 can not beneﬁt from all in-\ndecoding features and phenomenon like reorder-\ning.\nIt transliterates Urdu compound\n(Arabian Sea) to “Sea Arabian”, if\nis an un-\nknown word. In method 3, we feed the translitera-\ntion phrase-table directly into the ﬁrst-pass decod-\ning which allows reordering of UNK words. We\n1Mining algorithm also makes this assumption.\n2Tuning data is subtracted from the training corpus while\ntuning to avoid over-ﬁtting. After the weights are tuned, we\nadd it back, retrain GIZA, and estimate new models.\n149\n\n\nuse the decoding-graph-backoff option in Moses,\nthat allows multiple translation phrase tables and\nback-off models. As in method 2, we also use the\nLM-OOV feature in method 3.3\n5\nEvaluation\nData:\nWe experimented with 7 language pairs,\nnamely: Arabic, Bengali, Farsi, Hindi, Russian,\nTelugu and Urdu-into-English. For Arabic4 and\nFarsi, we used the TED talks data (Cettolo et al.,\n2012) made available for IWSLT-13, and we used\nthe dev2010 set for tuning and the test2011 and\ntest2012 sets for evaluation. For Indian languages\nwe used the Indic multi-parallel corpus (Post et\nal., 2012), and we used the dev and test sets pro-\nvided with the parallel corpus. For Russian, we\nused WMT-13 data (Bojar et al., 2013), and we\nused half of the news-test2012 for tuning and other\nhalf for testing. We also evaluated on the news-\ntest2013 set.\nFor all, we trained the language\nmodel using the monolingual WMT-13 data. See\nTable 1 for data statistics.\nLang\nTraintm\nTraintr\nDev\nTest1\nTest2\nAR\n152K\n6795\n887\n1434\n1704\nBN\n24K\n1916\n775\n1000\nFA\n79K\n4039\n852\n1185\n1116\nHI\n39K\n4719\n1000\n1000\nRU\n2M\n302K\n1501\n1502\n3000\nTE\n45K\n4924\n1000\n1000\nUR\n87K\n9131\n980\n883\nTable 1: No. of sentences in Training Data and\nMined Transliteration Corpus (Types) (Traintr)\nBaseline Settings:\nWe trained a Moses system\nreplicating the settings used in competition-grade\nsystems (Durrani et al., 2013b; Birch et al., 2013):\na maximum sentence length of 80, GDFA sym-\nmetrization of GIZA++ alignments (Och and Ney,\n2003), an interpolated Kneser-Ney smoothed 5-\ngram language model with KenLM (Heaﬁeld,\n2011) used at runtime, a 5-gram OSM (Dur-\nrani et al., 2013a), msd-bidirectional-fe lexical-\n3Method 3 is desirable in cases where the decoder can\ntranslate or transliterate a word. For example Hindi word\ncan be translated to “Border” and also transliterated\nto name “Seema”. Identifying such candidates that can be\ntranslated or transliterated is a challenge. Machine learning\ntechniques (Goldwasser and Roth, 2008; Kirschenbaum and\nWintner, 2009) and named entity recognizers (Klementiev\nand Roth, 2006; Hermjakob et al., 2008) have been used for\nthis purpose. Though, we only focus on OOV words, method\n3 can be used if such a classiﬁer/NE tagger is available.\n4Arabic and Urdu are segmented using MADA (Habash\nand Sadat, 2006) and UWS (Durrani and Hussain, 2010).\nized reordering, sparse lexical and domain fea-\ntures (Hasler et al., 2012), a distortion limit of\n6, 100-best translation options, MBR decoding\n(Kumar and Byrne, 2004), Cube Pruning (Huang\nand Chiang, 2007), and the no-reordering-over-\npunctuation heuristic. We tuned with the k-best\nbatch MIRA (Cherry and Foster, 2012).5\nTransliteration\nMiner:\nThe\nminer\nextracts\ntransliterations from a word-aligned parallel cor-\npus. We only used word pairs with 1-to-1 align-\nments.6 Before feeding the list into the miner, we\ncleaned it by removing digits, symbols, word pairs\nwhere source or target is composed from less than\n3 characters, and words containing foreign char-\nacters that do not belong to this scripts. We ran\nthe miner with 10 iterations of EM. The number\nof transliteration pairs (types) extracted for each\nlanguage pair is shown in Table 1 (Traintr).\nTransliteration System:\nBefore evaluating our\nintegrations into the SMT system, we performed\nan intrinsic evaluation of the transliteration system\nthat we built from the mined pairs. We formed\ntest data for Arabic–English (1799 pairs), Hindi–\nEnglish (2394 pairs) and Russian–English (1859\npairs) by concatenating the seed data and gold\nstandard transliteration pairs both provided for the\nShared Task on Transliteration mining (Kumaran\net al., 2010). Table 2 shows precision and recall of\nthe mined transliteration system (MTS).\nAR\nHI\nRU\nPrecision (1-best Accuracy)\n20.0%\n25.3%\n46.1%\nRecall (100-best Accuracy)\n80.2%\n79.3%\n87.5%\nTable 2: Precision and Recall of MTS\nThe precision (1-best accuracy) of the translit-\neration model is quite low. This is because the\ntransliteration corpus is noisy and contains imper-\nfect transliteration pairs. For example, the miner\nextracted the pair (\n, Australasia), while\nthe correct transliteration is “Australia”. We can\nimprove the precision by tightening the mining\nthreshold probability. However, our end goal is to\nimprove end-to-end MT and not the transliteration\nsystem. We observed that recall is more important\nthan precision for overall MT quality. We provide\nan empirical justiﬁcation for this when discussing\nthe ﬁnal experiments.\n5Retuning the transliteration features was not helpful, de-\nfault weights are used.\n6M-N/1-N alignments are less likely to be transliterations.\n150\n\n\nMT Experiments:\nTable 3 gives a comprehen-\nsive evaluation of the three methods of integra-\ntion discussed in Section 4 along with the num-\nber7 of OOV words (types) in different tests. We\nreport BLEU gains (Papineni et al., 2002) obtained\nby each method. Method 1 (M1), that replaces\nOOV words with 1-best transliteration gave an av-\nerage improvement of +0.13. This result can be at-\ntributed to the low precision of the transliteration\nsystem (Table 2). Method 2 (M2), that translit-\nerates OOVs in second pass monotonic decoding,\ngave an average improvement of +0.39. Slightly\nhigher gains were obtained using Method 3 (M3),\nthat integrates transliteration phrase-table inside\ndecoder on the ﬂy. However, the efﬁcacy of M3 in\ncomparison to M2 is not as apparent, as M2 pro-\nduced better results than M3 in half of the cases.\nLang\nTest\nB0\nM1\nM2\nM3\nOOV\nAR\niwslt11\n26.75\n+0.12\n+0.36\n+0.25\n587\niwslt12\n29.03\n+0.10\n+0.30\n+0.27\n682\nBN\njhu12\n16.29\n+0.12\n+0.42\n+0.46\n1239\nFA\niwslt11\n20.85\n+0.10\n+0.40\n+0.31\n559\niwslt12\n16.26\n+0.04\n+0.20\n+0.26\n400\nHI\njhu12\n15.64\n+0.21\n+0.35\n+0.47\n1629\nRU\nwmt12\n33.95\n+0.24\n+0.55\n+0.49\n434\nwmt13\n25.98\n+0.25\n+0.40\n+0.23\n799\nTE\njhu12\n11.04\n-0.09\n+0.40\n+0.75\n2343\nUR\njhu12\n23.25\n+0.24\n+0.54\n+0.60\n827\nAvg\n21.9\n+0.13\n+0.39\n+0.41\n950\nTable 3:\nEnd-to-End MT Evaluation – B0 =\nBaseline, M1 = Method1, M2 = Method2, M3 =\nMethod3, BLEU gains shown for each method\nIn an effort to test whether improving translit-\neration precision would improve end-to-end SMT\nresults, we carried out another experiment. Instead\nof building a transliteration system from mined\ncorpus, we built it using the gold standard corpus\n(for Arabic, Hindi and Russian), that we also used\npreviously to do an intrinsic evaluation. We then\nreplaced our mined transliteration systems with\nthe gold standard transliteration systems, in the\nbest performing SMT systems for these languages.\nTable 4 shows a comparison of performances. Al-\nthough the differences are small, systems using\nmined transliteration system (MTS) outperformed\nits counterpart that uses gold standard translitera-\ntion system (GTS), except in Hindi–English where\n7Note that not all OOVs can be transliterated. This num-\nber is therefore an upper bound what can be transliterated.\nboth systems were equal.\nAR\nHI\nRU\niwslt11\niwslt12\njhu12\nwmt12\niwslt13\nMTS\n27.11\n29.33\n16.11\n34.50\n26.38\nGST\n26.99\n29.20\n16.11\n34.33\n26.22\nTable 4: Comparing Gold Standard Transliteration\n(GST) and Mined Transliteration Systems\nIn the error analysis we found that the GST\nsystem suffered from sparsity and did not pro-\nvide enough coverage of rules to produce right\ntransliterations.\nFor example, Arabic drops the\ndeterminer\n(al), but such additions were not\nobserved in gold transliteration pairs.\nArabic\nword\n(Gigapixel) is therefore translit-\nerated to “algegabksl”. Similarly the GST system\nlearned no transliteration pairs to account for the\nrule “b →p” and therefore erroneously translit-\nerated\n(Spurlock) to “Sbrlok”.\nSimilar\nobservations were true for the case of Russian–\nEnglish. The rules “a →u” and “y →ϵ” were not\nobserved in the gold set, and hence\n(hurricane) was transliterated to “herricane” and\n(Talbot) to “Talboty”. This shows that\nbetter recall obtained from the mined pairs led to\noverall improvement.\n6\nConclusion\nWe incorporated unsupervised transliteration min-\ning model into standard MT pipeline to automati-\ncally transliterate OOV words without needing ad-\nditional resources. We evaluated three methods\nfor integrating transliterations on 7 language pairs\nand showed improvements ranging from 0.23-0.75\n(∆0.41) BLEU points. We also showed that our\nmined transliteration corpus provide better recall\nand overall translation quality compared to the\ngold standard transliteration corpus.\nThe unsu-\npervised transliteration miner and its integration\nto SMT has been made available to the research\ncommunity via the Moses toolkit.\nAcknowledgments\nWe wish to thank the anonymous reviewers and\nKareem Darwish for their valuable feedback on\nan earlier draft of this paper. The research lead-\ning to these results has received funding from\nthe European Union Seventh Framework Pro-\ngramme (FP7/2007-2013) under grant agreement\nn ◦287658. This publication only reﬂects the au-\nthors’ views.\n151\n\n\nReferences\nYaser Al-Onaizan and Kevin Knight. 2002. Translat-\ning Named Entities Using Monolingual and Bilin-\ngual Resources. In Proceedings of the 40th Annual\nMeeting of the Association for Computational Lin-\nguistics.\nMahmoud Azab, Houda Bouamor, Behrang Mohit, and\nKemal Oﬂazer. 2013. Dudley North visits North\nLondon: Learning When to Transliterate to Arabic.\nIn Proceedings of the 2013 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\npages 439–444, Atlanta, Georgia, June. Association\nfor Computational Linguistics.\nAlexandra Birch, Nadir Durrani, and Philipp Koehn.\n2013. Edinburgh SLT and MT System Description\nfor the IWSLT 2013 Evaluation.\nIn Proceedings\nof the 10th International Workshop on Spoken Lan-\nguage Translation, pages 40–48, Heidelberg, Ger-\nmany, December.\nOndrej Bojar, Christian Buck, Chris Callison-Burch,\nChristian\nFedermann,\nBarry\nHaddow,\nPhilipp\nKoehn, Christof Monz, Matt Post, Radu Soricut,\nand Lucia Specia.\n2013.\nFindings of the 2013\nWorkshop on Statistical Machine Translation.\nIn\nEighth Workshop on Statistical Machine Transla-\ntion, WMT-2013, pages 1–44, Soﬁa, Bulgaria.\nMauro Cettolo, Christian Girardi, and Marcello Fed-\nerico. 2012. WIT3: Web Inventory of Transcribed\nand Translated Talks.\nIn Proceedings of the 16th\nConference of the European Association for Ma-\nchine Translation (EAMT), pages 261–268, Trento,\nItaly, May.\nColin Cherry and George Foster. 2012. Batch Tun-\ning Strategies for Statistical Machine Translation. In\nProceedings of the 2012 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\npages 427–436, Montr´eal, Canada, June. Associa-\ntion for Computational Linguistics.\nKareem Darwish. 2010. Transliteration Mining with\nPhonetic Conﬂation and Iterative Training. In Pro-\nceedings of the 2010 Named Entities Workshop, Up-\npsala, Sweden.\nNadir Durrani and Sarmad Hussain. 2010. Urdu Word\nSegmentation. In Human Language Technologies:\nThe 2010 Annual Conference of the North American\nChapter of the Association for Computational Lin-\nguistics, pages 528–536, Los Angeles, California,\nJune. Association for Computational Linguistics.\nNadir Durrani, Hassan Sajjad, Alexander Fraser, and\nHelmut Schmid.\n2010.\nHindi-to-Urdu Machine\nTranslation through Transliteration. In Proceedings\nof the 48th Annual Conference of the Association for\nComputational Linguistics, Uppsala, Sweden.\nNadir Durrani, Alexander Fraser, Helmut Schmid,\nHieu Hoang, and Philipp Koehn.\n2013a.\nCan\nMarkov Models Over Minimal Translation Units\nHelp Phrase-Based SMT?\nIn Proceedings of the\n51st Annual Meeting of the Association for Compu-\ntational Linguistics, Soﬁa, Bulgaria, August. Asso-\nciation for Computational Linguistics.\nNadir Durrani, Barry Haddow, Kenneth Heaﬁeld, and\nPhilipp Koehn. 2013b. Edinburgh’s Machine Trans-\nlation Systems for European Language Pairs.\nIn\nProceedings of the Eighth Workshop on Statistical\nMachine Translation, Soﬁa, Bulgaria, August. As-\nsociation for Computational Linguistics.\nDan Goldwasser and Dan Roth. 2008. Active Sam-\nple Selection for Named Entity Transliteration. In\nProceedings of ACL-08: HLT, Short Papers, pages\n53–56, Columbus, Ohio, June. Association for Com-\nputational Linguistics.\nNizar Habash and Fatiha Sadat.\n2006.\nArabic Pre-\nprocessing Schemes for Statistical Machine Transla-\ntion. In Proceedings of the Human Language Tech-\nnology Conference of the NAACL, Companion Vol-\nume: Short Papers, pages 49–52, New York City,\nUSA, June. Association for Computational Linguis-\ntics.\nNizar Habash. 2009. REMOOV: A Tool for Online\nHandling of Out-of-Vocabulary Words in Machine\nTranslation. In Proceedings of the Second Interna-\ntional Conference on Arabic Language Resources\nand Tools, Cairo, Egypt, April. The MEDAR Con-\nsortium.\nEva Hasler, Barry Haddow, and Philipp Koehn. 2012.\nSparse Lexicalised Features and Topic Adaptation\nfor SMT.\nIn Proceedings of the seventh Interna-\ntional Workshop on Spoken Language Translation\n(IWSLT), pages 268–275.\nKenneth Heaﬁeld. 2011. KenLM: Faster and Smaller\nLanguage Model Queries.\nIn Proceedings of the\nSixth Workshop on Statistical Machine Translation,\npages 187–197, Edinburgh, Scotland, United King-\ndom, 7.\nUlf Hermjakob, Kevin Knight, and Hal Daum´e III.\n2008.\nName Translation in Statistical Machine\nTranslation - Learning When to Transliterate.\nIn\nProceedings of the 46th Annual Meeting of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, Columbus, Ohio.\nLiang Huang and David Chiang. 2007. Forest Rescor-\ning:\nFaster Decoding with Integrated Language\nModels. In Proceedings of the 45th Annual Meet-\ning of the Association of Computational Linguistics,\npages 144–151, Prague, Czech Republic, June. As-\nsociation for Computational Linguistics.\nSittichai\nJiampojamarn,\nKenneth\nDwyer,\nShane\nBergsma, Aditya Bhargava, Qing Dou, Mi-Young\nKim, and Grzegorz Kondrak. 2010. Transliteration\n152\n\n\nGeneration and Mining with Limited Training Re-\nsources. In Proceedings of the 2010 Named Entities\nWorkshop, Uppsala, Sweden.\nAli El Kahki, Kareem Darwish, Ahmed Saad El Din,\nand Mohamed Abd El-Wahab.\n2012.\nTransliter-\nation Mining Using Large Training and Test Sets.\nIn Proceedings of the 2012 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nNAACL HLT ’12.\nMehdi M. Kashani, Eric Joanis, Roland Kuhn, George\nFoster, and Fred Popowich. 2007. Integration of\nan Arabic Transliteration Module into a Statistical\nMachine Translation System. In Proceedings of the\nSecond Workshop on Statistical Machine Transla-\ntion, Prague, Czech Republic.\nAmit Kirschenbaum and Shuly Wintner. 2009. Lightly\nSupervised Transliteration for Machine Translation.\nIn Proceedings of the 12th Conference of the Euro-\npean Chapter of the ACL (EACL 2009), pages 433–\n441, Athens, Greece, March. Association for Com-\nputational Linguistics.\nAlexandre Klementiev and Dan Roth. 2006. Named\nentity transliteration and discovery from multilin-\ngual comparable corpora.\nIn Proceedings of the\nHuman Language Technology Conference of the\nNAACL, Main Conference, pages 82–88, New York\nCity, USA, June. Association for Computational\nLinguistics.\nPhilipp Koehn, Hieu Hoang, Alexandra Birch, Chris\nCallison-Burch, Marcello Federico, Nicola Bertoldi,\nBrooke Cowan,\nWade Shen,\nChristine Moran,\nRichard Zens, Chris Dyer, Ondrej Bojar, Alexandra\nConstantin, and Evan Herbst. 2007. Moses: Open\nSource Toolkit for Statistical Machine Translation.\nIn Proceedings of the 45th Annual Meeting of the\nAssociation for Computational Linguistics, Demon-\nstration Program, Prague, Czech Republic.\nShankar Kumar and William J. Byrne. 2004. Mini-\nmum Bayes-Risk Decoding for Statistical Machine\nTranslation. In HLT-NAACL, pages 169–176.\nA Kumaran, Mitesh M. Khapra, and Haizhou Li. 2010.\nWhitepaper of news 2010 shared task on transliter-\nation mining. In Proceedings of the 2010 Named\nEntities Workshop, pages 29–38, Uppsala, Sweden,\nJuly. Association for Computational Linguistics.\nJae-Sung Lee and Key-Sun Choi.\n1998.\nEnglish\nto Korean Statistical Transliteration for Information\nRetrieval.\nComputer Processing of Oriental Lan-\nguages, 12(1):17–37.\nWen-Pin Lin, Matthew Snover, and Heng Ji.\n2011.\nUnsupervised Language-Independent Name Trans-\nlation Mining from Wikipedia Infoboxes. In Pro-\nceedings of the First workshop on Unsupervised\nLearning in NLP, pages 43–52, Edinburgh, Scot-\nland, July. Association for Computational Linguis-\ntics.\nPreslav Nakov and J¨org Tiedemann.\n2012.\nCom-\nbining Word-Level and Character-Level Models for\nMachine Translation Between Closely-Related Lan-\nguages. In Proceedings of the 50th Annual Meet-\ning of the Association for Computational Linguis-\ntics (Volume 2: Short Papers), pages 301–305, Jeju\nIsland, Korea, July. Association for Computational\nLinguistics.\nFranz J. Och and Hermann Ney. 2003. A Systematic\nComparison of Various Statistical Alignment Mod-\nels. Computational Linguistics, 29(1).\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu.\n2002.\nBLEU: a method for automatic\nevaluation of machine translation. In Proceedings of\nthe 40th Annual Meeting on Association for Compu-\ntational Linguistics, ACL ’02, pages 311–318, Mor-\nristown, NJ, USA.\nMatt Post, Chris Callison-Burch, and Miles Osborne.\n2012. Constructing Parallel Corpora for Six Indian\nLanguages via Crowdsourcing. In Proceedings of\nthe Seventh Workshop on Statistical Machine Trans-\nlation, pages 401–409, Montr´eal, Canada, June. As-\nsociation for Computational Linguistics.\nHassan Sajjad, Alexander Fraser, and Helmut Schmid.\n2011. An Algorithm for Unsupervised Translitera-\ntion Mining with an Application to Word Alignment.\nIn Proceedings of the 49th Annual Conference of\nthe Association for Computational Linguistics, Port-\nland, USA.\nHassan Sajjad, Alexander Fraser, and Helmut Schmid.\n2012.\nA Statistical Model for Unsupervised and\nSemi-supervised Transliteration Mining.\nIn Pro-\nceedings of the 50th Annual Conference of the Asso-\nciation for Computational Linguistics, Jeju, Korea.\nTarek Sherif and Grzegorz Kondrak. 2007. Bootstrap-\nping a Stochastic Transducer for Arabic-English\nTransliteration Extraction.\nIn Proceedings of the\n45th Annual Meeting of the Association for Compu-\ntational Linguistics, Prague, Czech Republic.\nBing Zhao, Nguyen Bach, Ian Lane, and Stephan Vo-\ngel.\n2007.\nA Log-Linear Block Transliteration\nModel based on Bi-Stream HMMs.\nIn Human\nLanguage Technologies 2007: The Conference of\nthe North American Chapter of the Association for\nComputational Linguistics, Rochester, New York.\n153"
    }
]