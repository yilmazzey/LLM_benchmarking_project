[
  {
    "conversations": [
      {
        "role": "user",
        "content": "Write me an abstract for this article: Title: argument-based_detection_and_classification_of_fallacies_in_political_debates\n\nSections:\nFallacious arguments have been firstly defined as\ndefective inferences, i.e., logically invalid types of\narguments (Eemeren, 2001). More recently, in a\nmore pragmatic perspective, fallacious arguments\nhave been defined as infringements of performance\nrules characteristic of a particular ideal type of argumentative engagement (Eemeren and Grootendorst,\n1987) and as illicit dialectical shifts across different dialogue types, highlighting that the attempted\n\n\nmove is inappropriate with respect to its pragmatic\napplication context (Walton, 1995). Despite their\nemployment in many scenarios (e.g., online discussion platforms and blogs, TV roundtables), a\nnatural testbed of this form of misleading argumentation is political debate. For instance, the *ad*\n*hominem* fallacy, where the plausibility of the argument depends on the credentials, personal background and past actions of the speaker, is probably\none of the fallacy labels that is most often thrown\naround in political debate. This kind of arguments\nmay sound convincing and has the goal to mislead\nthe audience, persuading it about the validity of\nthe argument. Given the potential nefarious impact of these misleading arguments on the society,\nidentifying and classifying fallacious arguments is\ntherefore a main open challenge in Argument Mining (AM) (Cabrio and Villata, 2018; Lawrence and\nReed, 2019; Lauscher et al., 2022), and in NLP in\ngeneral.\n\nExisting approaches in the literature (Habernal\net al., 2017, 2018; Goffredo et al., 2022; Vijayaraghavan and Vosoughi, 2022; Alhindi et al.,\n2022; Vorakitphan et al., 2022; Sahai et al., 2021)\nmainly concentrated on the classification of fallacious text snippets over a finite set of labels, leaving\nthe challenging issue of identifying the fallacious\ntext snippet and its boundaries under-investigated.\nIn this paper, we tackle this open research question on a dataset of political debates from the U.S.\npresidential campaigns from 1960 to 2020.\n\nMore precisely, the contribution of this paper is\ntwofold. First, we extend an existing resource of\nU.S. political debates from the presidential campaigns (1960-2016) annotated both with argument\ncomponents and relations, and six fallacy categories (namely, *Ad Hominem, Appeal to Author-*\n*ity, Appeal to Emotion, False Cause, Slippery*\n*Slope and Slogans* ). This new resource, named\nthe ElecDeb60to20 dataset, includes now also the\ndebates of the 2020 presidential campaign (Trump\n\n11101\n\n*Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing*, pages 11101–11112\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\n\n\n-----\n\nBiden) with all the related annotations. Second, we\npropose a new approach, based on Transformers,\nto detect the fallacious text snippets in these debates, and then classify them along the six fallacy\ncategories. This approach encodes the argument\ncomponents (i.e., *Premise, Claim* ), the argument\nrelations (i.e., *Support, Attack* ) and the PoS tags\nto successfully identify and classify fallacious arguments. Experimental results show that the proposed approach outperforms standard baselines and\nconcurrent approaches with an average f1-score of\n0 *.* 74, with our proposed model named MultiFusion\nBERT, on the task of fallacious argument detection\nand classification.\nWhilst most of the computational approaches targeting fallacious argumentation focus on the pure\nclassification of such nefarious content (Habernal\net al., 2017, 2018; Jin et al., 2022; Goffredo et al.,\n2022; Vijayaraghavan and Vosoughi, 2022; Alhindi\net al., 2022), the originality of our contribution is\nthat it proposes, to the best of our knowledge, the\nfirst neural architecture to both detect fallacious arguments and classify them in political debates, and\none of the very few approaches to tackle this task in\ngeneral, outperforming competing approaches (Vorakitphan et al., 2022; Sahai et al., 2021).\nThe urgency to study fallacies in political discourse is crucial both from the philosophical and\nthe political perspective. It emphasizes the need\nto scrutinize political arguments for sound reasoning rather than deception. Understanding logical\nflaws is a main issue for informed decision-making,\nenabling the recognition and assessment of fallacious arguments in political discourse. Moreover,\nexamining how fallacies are employed in political\ndebates reveals their strategic role in influencing\nopinion and diverting attention. This strategic use\nof fallacies mirrors the subtleties of language, emphasizing the interplay between rhetoric, philosophy, and political communication. Furthermore, it\noffers valuable insights into the dynamics of public\ndiscourse and the need for critical analysis (Walton,\n1987, 1995).\n## **2 Related Work**\n\nOver the years, there has been a growing interest\nin the field of NLP to the detection of fallacies and\nrelated phenomena, including misinformation and\npropaganda (Da San Martino et al., 2020b). The\npioneering work of Da San Martino et al. (2019b)\non fallacies in newspaper news has been a signif\n\nicant source of inspiration in this area. Recently,\nresearchers have made significant progress in identifying and classifying fallacies within discourse.\nIn this section, we discuss the approaches proposed\nin the literature on the two tasks of fallacy classification (Section 2.1) and fallacy detection (Section 2.2).\n\n**2.1** **Fallacy Classification**\n\nFor instance, Habernal et al. (2017) aimed to improve fallacy detection by creating a publicly available software called “Argotario”. It serves as an\neducational gaming platform and a means to gather\ndata from the crowd for annotating fallacy types in\neveryday arguments. In a subsequent study, Habernal et al., 2018 released annotated datasets of fallacious arguments in English and German. They conducted experiments using Support Vector Machine\nand BiLSTM models with German word vectors to\n\nclassify six fallacious topic types (accuracy=50.9%,\nmacro-F1 score=42.1%).\n\nJin et al. (2022) proposes an architecture based\non a simple classifier that incorporates the structural information of fallacies. They augment a\nstandard pre-trained language model for classification with a template that includes modified assumptions and premises based on a well-defined\nmasking scheme. They achieve an F1 score of\n58.77% on the classification task over 13 classes.\nThey used a dataset collected from online teaching\nmaterials, specifically designed to teach and test\nstudents’ understanding of logical fallacies.\n\nIn a more contextual approach, Goffredo et al.\n(2022) use a dataset from U.S. Presidential Elec\ntion Debates From 1960 to 2016. This dataset\n\nincorporates information such as the context and\nargumentative features (i.e., argument components\nand relations) for each fallacy. The proposed architecture uses one classifier for each feature in\norder to calculate the loss. On a sentence classification task encompassing six fallacy categories, their\napproach achieves an F1 score of 84%.\nTo address the identification and classification\nof fine-grained propaganda tweets, Vijayaraghavan and Vosoughi (2022) proposed an end-to-end\ntransformers-based approach that considers additional features like context, relational information, and external knowledge through data augmentation. Their dataset consists of approximately\n211K tweets annotated with 19 classes (18 propaganda types and 1 non-propaganda). The approach\n\n\n11102\n\n\n-----\n\nyielded a 64% F1 score on a text classification task.\n\nAlhindi et al. (2022) introduced an instructionbased prompt in a multitask configuration using\nthe T5 model to classify fallacies. This methodology involved leveraging multiple fallacy-based\ndatasets, including Propaganda (Da San Martino\net al., 2019b), Logic (Jin et al., 2022), Argotario\n(Habernal et al., 2017), Covid-19 (Musi et al.,\n2022), and Climate (Jin et al., 2022). Their approach enabled the identification of 28 distinct fallacies across various domains and genres, facilitating the analysis of model size and prompt selection,\nand investigating the impact of annotation quality\non model performance, potentially supplemented\nwith external knowledge. The results obtained using their T5-large model yielded F1 scores of 41%\nfor Propaganda, 62% for Logic, 59% for Argotario,\n26% for Covid-19, and 17% for Climate, respectively.\n\n**2.2** **Fallacy Detection and Classification Task**\n\nVorakitphan et al. (2022) proposes a system capable of automatically identifying propaganda messages and classifying them based on the propaganda techniques employed. The system adopts a\npipeline approach that firstly detects the text snippet containing potential propaganda, and then performs classification by leveraging semantic and\nargumentative features. Two standard benchmarks,\nNLP4IF’19 (Da San Martino et al., 2019a) and SemEval’20 datasets (Da San Martino et al., 2020a),\nwere used for this propaganda detection and classification task. The binary classification step, utilizing BERT, achieved a 72% F1 score, while the\nsentence-span multi-class classification task (14\nclasses) achieved a 64% micro F1 score using a\nRoBERTa-based architecture.\nFallacy detection and token-level classification\ntasks were also performed in Sahai et al. (2021).\nThey narrowed their study to 8 fallacy types and\ncreated a corpus of fallacious arguments by annotating user comments on Reddit. They performed\nfallacy classification at comment-level and tokenlevel, relying on BERT and MGN (Da San Martino\net al., 2019a) models. The inclusion of the conversation context, represented by the parent comment\nor submission title, was used to enhance the predictions. Fine-tuned BERT with a classification\nhead of a linear layer reported the best results on\nthe token classification task (macro F1=53%).\nOur present work expands the scope of these\n\n\nfallacy studies in several ways. Firstly, we employ\na corpus specifically created for fallacy detection\nin political debates, which has been under investigated in this context even though fallacious argumentation is a main issue in political discourse.\nSecondly, while the majority of existing studies focus on fallacy classification, in this paper we focus\non the fallacy detection task, which is of main importance in real-life scenarios where text or speech\nlacks pre-segmentation and a clear binary classification into fallacies or non-fallacies. Lastly, our\nstudy capitalizes on the annotations of argumentation features in our dataset, an element that is\noften absent in other corpora, allowing us to go\nbeyond pure text-based approaches, and to rely on\nthe argumentation structure.\n## **3 ElecDeb60to20 Dataset**\n\nTo effectively address the task of detecting and\nclassifying fallacious arguments within political\ndebates, we decided to rely on the ElecDeb60To16\ndataset (Haddadan et al., 2019; Goffredo et al.,\n2022). It comprises televised debates from U.S.\npresidential election campaigns spanning from\n1960 to 2016. These debates were sourced from\n\nthe website of the Commission on Presidential\nDebates [1], which openly provides transcripts of\ndebates broadcasted on television and featuring\nthe prominent candidates for presidential and vicepresidential nominations in the United States. All\ninformation on this website is accessible to the\n\npublic. Considering the most recent presidential\nelection between Trump and Biden occurred in\n2020, we expanded the dataset with the transcripts\nof the debates of this election campaign to include\nupdated annotations, incorporating argumentative\ncomponents such as *Claims* and *Premises*, as well\nas the relations between these components, i.e.,\n*Support* and *Attack* . As a result of this annotation\nupdate, the dataset is renamed as ElecDeb60to20 [2],\nreflecting the coverage of debates spanning from\n1960 to 2020. This updated dataset provides a more\ncomprehensive and contemporary collection of fallacies in political debates, enhancing the relevance\nand applicability of the data for further analysis\nand research in the field.\nThis resource is a valuable benchmark for investigating potential connections between specific\n\n1 [https://www.debates.org/voter-education/](https://www.debates.org/voter-education/debate-transcripts/)\n[debate-transcripts/](https://www.debates.org/voter-education/debate-transcripts/)\n\n2 [https://github.com/pierpaologoffredo/](https://github.com/pierpaologoffredo/FallacyDetection)\n[FallacyDetection](https://github.com/pierpaologoffredo/FallacyDetection)\n\n\n11103\n\n\n-----\n\nargument components and relations that underlie\nthe occurrence of fallacious arguments.\n\n**3.1** **Annotated Fallacies**\n\nDuring the annotation process of fallacies within\nthe U.S. political debates of the 2020 presidential\nelection, we rely on the six categories based on the\nannotation scheme proposed by Da San Martino\net al. (2019a), the categorization outlined by Walton (1987), and the annotation of the previous debates in the first version of the dataset with these fallacy categories (Goffredo et al., 2022). Hence, we\nadopted the following categories: *Ad Hominem*, *Ap-*\n*peal to Authority*, *Appeal to Emotion*, *False Cause*,\n*Slippery Slope*, and *Slogans* . Below, we provide a\nconcise description of each of these six categories.\n\n**Ad Hominem.** When the argument becomes an\nexcessive attack on an arguer’s position (Walton,\n1987).\n\n**Appeal to Emotion.** The unessential loading of\nthe argument with emotional language to exploit\nthe audience emotional instinct.\n\n**Appeal to Authority.** It occurs when the arguer\nrelies on the endorsement of an authority figure\nor a group consensus without providing sufficient\nevidence. It may also involve the citation of nonexperts or the majority to support their claim.\n\n**Slippery Slope.** This fallacy implies that an improbable or exaggerated consequence could result\nfrom a particular action.\n\n**False Cause.** The misinterpretation of the correlation of two events for causation (Walton, 1987).\n\n**Slogan.** It is a brief and striking phrase used to\nprovoke excitement of the audience, and is often\naccompanied by another type of fallacy called *ar-*\n*gument by repetition* .\n\n**3.2** **Annotation Phase**\n\nThe updated annotations were conducted following the annotation scheme introduced in Haddadan\net al. (2019); Goffredo et al. (2022). Following this\napproach, each debate was divided into sections,\nstarting with either a moderator/panelist or an audience member asking a question on a new topic.\nTo facilitate the annotation process, the semantic\nannotation platform INCEpTION (Klie et al., 2018)\nwas used.\n\n\nTwo annotators, with expertise in computational\nlinguistics, independently annotated the new portion of the dataset (Trump vs. Biden debates) by\nidentifying argumentative components, relations,\nand fallacies. To maintain objectivity and prevent\nbias, the annotation process for argumentative components was performed on raw data, without any\npre-existing fallacy annotations. This approach\nwas adopted to ensure that the annotation process\nremains unbiased and free from any preconceived\nnotions related to fallacies. A set of 50 sentences\n\nrandomly extracted from the debates was annotated\nto assess Inter-Annotator Agreement (IAA), and\nthe results, visualized in Table 1, indicate a substantial level of agreement between the annotators.\n\n**Measure** **Value**\n\nObserved Agreement 0.857\nKrippendorff’s *α* 0.757\n\nTable 1: IAA agreement over 50 sentences randomly\nextracted from the debates Trump-Biden.\n\n**3.3** **Statistics and Data Analysis**\n\nTable 2 summarizes the Trump vs. Biden’s debates annotations per category and argumentative\nfeatures. We tokenized the annotated fallacious ar\nguments to compute the average number of words\nin each category. In line with the guidelines of\nGoffredo et al. (2022), *Slogans* is the shortest with\n5.0 tokens on average [3], whereas *SlipperySlope* was\nthe longest with 20.5 tokens on average.\n\n|Category Freq AvgTok|Arg. Feature Freq|\n|---|---|\n|Ad Hominem 62 4,6 AppealtoAuthority 17 18,6 AppealtoEmotion 147 6,81 FalseCause 0 0 SlipperySlope 4 20,5 Slogans 2 5|Claims 1513 Premise 332 Support Rel. 400 Attack Rel. 112|\n|Total 232 9,25|Total 2357|\n\n\n\nTable 2: Distribution of annotated fallacies per category and argumentative features of Trump vs. Biden’s\ndebates.\n\nThe train and test set split was performed considering the entire new dataset ElecDeb60to20. The\ntraining set accounts for 90% of the dataset, while\nthe remaining 10% constitutes the test set. The\ndistribution of fallacy labels is as follows: *Appeal-*\n*toEmotion* ( 59 *.* 94% ), *AppealtoAuthority* ( 15 *.* 20% ),\n\n3 *Slogan* is by definition a short and striking phrase.\n\n\n11104\n\n\n-----\n\n*AdHominem* ( 13 *.* 58% ), *FalseCause* ( 46 *.* 93% ), *Slip-*\n*peryslope* ( 3 *.* 97% ), and *Slogans* ( 2 *.* 63% ). In the\nlast debate, the most used fallacies are *AppealtoE-*\n*motion* and *AdHominem*, confirming the trend of\nthe previous debates. Behind this strategy, there\nare many references to the COVID-19 pandemic\nand some personal issues of the two candidates exploited during the debates. Despite being distinct\nand unrelated, these two topics held significant importance and consistently fueled intense debates.\n## **4 Fallacy Detection**\n\nWe cast the fallacy detection task as an information\nextraction problem, where the goal is to identify\nand classify in the debates the textual snippets corresponding to the six categories of fallacies annotated in the context of a political debate (see Section\n3.1 for the list of fallacies and their description).\nWe rely on the *BIO* / *IOB* data format, and specific\ntags are assigned to annotate the fallacies, i.e., *B-*\n*AdHominem*, *I-AdHominem*, *B-AppealtoAuthority*,\n*I-AppealtoAuthority*, *B-AppealtoEmotion*, *I-*\n*AppealtoEmotion*, *B-FalseCause*, *I-FalseCause*,\n*B-Slipperyslope*, *I-Slipperyslope*, *B-Slogans*,\n*I-Slogans*, *O* .\nThe fallacy detection and classification tasks consist therefore in assigning one of these thirteen predefined labels to each token.\nTo have a richer representation of fallacy annotations, we build a contextual framework that includes the sentence containing the fallacy, as well\nas the *preceding* and *following* sentences. When\nthe fallacious sentence is the first or last in the\ndialogue, the preceding or following sentence is\nexcluded.\n\n**4.1** **Method**\n\nTo address the above-mentioned tasks, we employ\ntransformer-based architectures in both their basic configuration and in a specialized configuration\ndesigned for token classification [4], drawing inspiration from previous studies on fallacy detection and\nclassification (Da San Martino et al., 2020a; Vorakitphan et al., 2022; Goffredo et al., 2022) that have\nprovided empirical evidence of the advantages of\ncomplementing transformer-generated text representations with non-textual features. Moreover, we\nenhance the specialized architecture by including\nadditional argumentative features.\n\n4 [https://huggingface.co/docs/transformers/](https://huggingface.co/docs/transformers/tasks/token_classification)\n[tasks/token_classification](https://huggingface.co/docs/transformers/tasks/token_classification)\n\n\n**4.1.1** **Baselines**\n\n**BERT + (Bi)LSTM(s)** The simplest models consist of a pre-trained BERT model followed by either *(i)* an LSTM layer and a dense layer, or *(ii)* a\nBiLSTM layer with 0.2 dropout, an LSTM layer,\nand a dense layer. The weights of the transformer\nare kept frozen during training. The text serves\nas input for the transformer, and we extract the\nlast hidden states (i.e., the embedded representation of each token). This output is then passed\non to the subsequent layers. In the case where\nargumentative features are included in the model,\nwe concatenate the last hidden states of the trans\nformer with the one-hot-encoded representation of\nthe argument components and relationships. This\nconcatenated feature representation is then fed into\nthe next RNN-based layers. All models used Adam\noptimizer with default PyTorch parameters.\n\nis a transformer**BertForTokenClassification**\nbased model relying on a bidirectional approach to capture contextual information\nfrom surrounding words. We tested two\ncheckpoints: bert base uncased and\nbert-large-cased-finetuned-conll03-engl.\n\nis based on a\n**DebertaForTokenClassification**\nmodified transformer architecture with improvements like “de-coupled attention” and “crosslayer parameter sharing” for enhanced language\nmodeling capabilities. The checkpoint used is\nmicrosoft/deberta-base.\n\nrelies on\n**ElectraForTokenClassification**\na novel pre-training method called \"discriminative pre-training,\" where a generator\nand a discriminator are trained to enhance\n\nthe quality of the learned representations.\nThe checkpoint used is: bhadresh-savani/\n\nelectra-base-discriminator-finetuned\nconll03-english.\n\nis a distilled\n**DistilbertForTokenClassification**\nversion of BERT that retains much of its\nperformance while significantly reducing the\nmodel size and computational resources required for training and inference. The checkpoint used are: distilbert-base-cased and\n\ndistilbert-base-uncased.\n\n**4.1.2** **MultiFusion BERT**\n\nRelying on the results obtained by the\nbaselines on the fallacy detection task on\n\n\n11105\n\n\n-----\n\n**Model** **Av** **g** **macro F1 Score**\n\nBERT + LSTM 0.4697\n\nBERT + LSTM (comp. and rel. features) 0.5142\n\nBERT + BiLSTM + LSTM 0.5495\n\nBERT + BiLSTM + LSTM (comp. and rel. features) 0.5614\n\nBertFTC bert-base-uncased 0.7096\n\nBertFTC **dbmdz/bert-large-cased-finetuned-conll03-english** **0.7237**\n\nDebertaFTC microsoft/deberta-base 0.7222\n\nElectraFTC bhadresh-savani/electra-base-discriminator-finetuned-conll03-english 0.4033\n\nDistilbertFTC distilbert-base-cased 0.7010\n\nDistilbertFTC distilbert-base-uncased 0.7047\n\nMultiFusion BERT (comp., rel. and PoS features) **0.7394**\n\nTable 3: Average macro F1 scores for fallacy detection (BIO labels are merged) using different models. The scores\nare based on an average of 3 runs, except for BERT + (Bi)LSTM(s) models, which were evaluated using 10 runs.\n(FTC stands for “ForTokenClassification)\n\n\n**Features** **Avg macro**\n**Com** **p** **onents** **Relationshi** **p** **s** **PoS** **F1 Score**\n\n✓ 0.6922\n\n✓ 0.6922\n\n✓ 0.7212\n\n✓ ✓ 0.7278\n\n✓ ✓ 0.7166\n\n✓ ✓ 0.7166\n\n✓ ✓ ✓ **0.7394**\n\nTable 4: Average macro F1 scores for fallacy detection\n(BIO labels are merged) using MultiFusion BERT and\ndifferent features. The scores are based on an average\nof 3 runs.\n\nthe ElecDeb60to20 dataset reported in\nTable 3 [5], we select the BertFTC model\n( bert-large-cased-finetuned-conll03-eng .)\nto be included in our proposed architecture.\nDespite the good performances of BertFTC,\nwe propose to enhance its capabilities to detect\nfallacious text by integrating and “fusing” additional features, namely argumentative components\n( *Claim, Premise* ), argumentative relations ( *Support,*\n*Attack* ), and Part-of-Speech (PoS) tags.\nArgumentative features were included to improve the model’s understanding of an argument\nunderlying structure, enabling it to detect when its\nlogical structure is compromised. Since fallacies\ninvolve faulty reasoning, we hypothesized that providing this information to the model would be relevant. Results in Table 4 provide empirical evidence\nto support this hypothesis. In particular, it has been\nshown that including argumentation features in\n5 The reported results represent the average performance\nbased on the macro average F1 score.\n\n\ncreases the model performances in the context of\nfallacy classification (Goffredo et al., 2022). Such\nfeatures can be extracted by specific annotations\nassociated with each fallacy in the ElecDeb60to20\ndataset: the type of argumentative component in\nwhich the fallacy may be present, and the argumentative relations among these different components.\n\nThe integration of PoS information is driven by\nthe observation that certain fallacies exhibit dis\ntinctive language patterns that can be more easily discerned using PoS tagging. For example,\nin the *LoadedLanguage* fallacy (a subcategory of\nthe *AppealToEmotion* category), the intensity of a\nsentence is often increased by using emotionally\nloaded phrases, expressed through the use of a sentiment lexicon, particularly concerning adjectives\nand adverbs. Similarly, in the *AdHominem* fallacy,\nwhere the focus shifts from attacking the argument\nto targeting the character, motives, or personal qualities of the political opponent, the reference to this\nopponent is expressed using a noun or pronoun\nand subsequently employs adjectives with negative\nconnotations.\n\nFigure 1 illustrates the proposed model, called\nMultiFusion BERT, for the detection and classification of fallacies in political debates. MultiFusion BERT computes logits ( *L* ) for each feature by employing a specialized *TokenForClassi-*\n*fication* Transformer model adapted to the number of labels: 3 for components and relations, and\n17 for part-of-speech tags. The architectures for\nargumentative features for components and relations share the same parameters, enabling us to\nobtain *logits* for both components and relations.\nAn additional model, based on the number of PoS\n\n\n11106\n\n\n-----\n\nFigure 1: MultiFusion BERT with *joint* *loss* approach.\n\ntags (i.e., 17), is used to obtain *logits* for PoS\nfeatures. Consequently, distinct losses are computed for each model: fallacy loss ( *loss* *fal* ), component loss ( *loss* *cmp* ), relation loss ( *loss* *rel* ), and\npart-of-speech loss ( *loss* *pos* ). These individual\nlosses are combined by multiplying them with\nan arbitrary *α* value of 0 *.* 1, yielding a unified\naverage loss referred to as the *joint* *loss* (Vorakitphan et al., 2021). In our study, we opted for\nempirically investigating the optimal alpha value\nthat yielded superior performance, as evidenced\nby our experiments (see Appendix D for the exhaustive evaluation). The back-propagation function incorporates all losses in the following way:\n*joint* *loss* = *α ∗* [(] *[loss]* *[f]* *[al]* [+] *[loss]* *[cm]* *N* *[p]* *loss* [+] *[loss]* *[rel]* [+] *[loss]* *[P oS]* [)],\n\nwhere *N* *loss* denotes the number of losses considered by the model. We conducted an exploration\nof various values for the *α* parameter.\n\n**4.2** **Experimental Setup**\n\nAll models have been fine-tuned using the\nElecDeb60to20 dataset. The implementation was\nbased on HuggingFace [6] version 4.30 . and on PyTorch 1.7.0 . All models utilize the Adam optimizer, with a gradient clipping set to 10, a dropout\nof 0 *.* 1, a learning rate of 4 *e−* 05 and a training batch\nsize of 8 and a test batch size of 4 . The training process consists of 4 epochs, during which the models\nare fine-tuned and optimized. The dataset was split\nwith 90% for training and 10% for testing, ensuring balanced distribution on the fallacy labels using\nstratification. The partitioning was performed using the train_and_test_split function from the\n\n6 [https://huggingface.co/docs/transformers/](https://huggingface.co/docs/transformers/index)\n[index](https://huggingface.co/docs/transformers/index)\n\n\nscikit-learn [7] library. The random seed was set to\n42 . The PoS tags were obtained using the spaCy [8]\n\nlibrary. The maximum tensor size is set to 256,\nensuring that all necessary text information is included without truncation. The representation of\nthis encoding is showed in the Appendix A.\n\nThe proposed neural architecture contains 328\nmillion parameters [9] . This large parameter count\nenables the model to capture intricate patterns and\ndependencies within the data, enhancing its capacity for complex information processing and generating more accurate predictions. We evaluated\nthe “MultiFusion” approach on the baseline model\nthat showed the best results. Despite having approximately half of the trainable parameters of\nBERT (e.g., 65M for DistilBERT vs. 109M for\nBERT), BERT outperformed DistilBERT. Consequently, we adopted BERT as the architecture for\nimplementing the approach described above. We\nutilized the Nvidia Quadro RTX 8000 GPU (32\nGB) for our experiments. The average runtime\nwas of 21 minutes for training and testing all the\nconfigurations of our models.\n## **5 Evaluation**\n\nTable 3 presents the results of the tested models for\nfallacies detection in the political debates. Results\nare calculated using the macro average F1 metric,\nconsidering the following fallacy labels: *(i)* Ad\nHominem, *(ii)* Appeal to Authority, *(iii)* Appeal\nto Emotion, *(iv)* False Cause, *(v)* Slippery Slope,\n*(vi)* Slogans, and *(vii)* Other ( *B* and *I* labels are\nmerged). Despite the relatively smaller size of\nthe dataset and the task complexity, the results obtained from the different models are promising. As\nintroduced before, among the baselines, BERT “ *db-*\n*mdz/ bert-large-cased-finetuned-conll03-english* ”\nachieved the best performance. Thus, MultiFusion BERT, incorporating argumentative features\n(components and relations) as well as PoS tags,\nsignificantly outperformed the other models (the\nperformance increase with respect to BertFTC is\nof 2.12%).\n\n7 [https://scikit-learn.org/stable/modules/](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n[generated/sklearn.model_selection.train_test_](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n[split.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n\n8 [https://spacy.io](https://spacy.io)\n9 The standard BertFTC model is around three times\nsmaller, approximately 109 million parameters.\n\n\n11107\n\n\n-----\n\n**5.1** **Ablation Tests**\n\nTo better analyze the impact of the different features incorporated in our architecture, we carried\nout ablation tests. Table 4 presents the results\nobtained by MultiFusion BERT using all possible combinations of *(i)* argumentative components,\n*(ii)* argumentative relations, and *(iii)* context PoS\ntags. Incorporating argumentative components, relations, and PoS features individually or in pairs\nresulted in a decline in performance compared to\nthe best baseline results (i.e., BertFTC “ *dbmdz/*\n*bert-large-cased-finetuned-conll03-eng.* ), with an\naverage degradation of 4 *.* 35% across the different\nconfigurations (excluding the one considering all\nthree features). In contrast, when all three features\nare included (as described in Section 4.1.2) a significant improvement in model performance is observed, highlighting the importance of considering\nall of them together for fallacy detection.\n\n**5.2** **Error Analysis**\n\n**Label** **p** **recision** **recall** **f1-score** **su** **pp** **ort**\n\nAdHominem 0.99 0.77 0.87 739\n\nAppealtoAuthority 0.90 0.78 0.83 1’049\nAppealtoEmotion 0.82 0.77 0.79 2’224\nFalseCause 0.82 0.86 0.84 321\n\nSlipperyslope 0.90 0.88 0.89 332\nSlogans 0.00 0.00 0.00 49\nO 0.90 0.95 0.93 7’914\n\naccuracy 0.89 12’628\nmacro avg 0.76 0.72 **0.74** 12’628\nwei g hted av g 0.89 0.89 0.89 12’628\n\nTable 5: Classification report of Fallacy Detection and\nClassification with *B* and *I* labels merged.\n\nTable 5 provides an in-depth analysis of MultiFusion BERT’s performances on the test set, considering the different target labels [10] . Notably, the\nidentification of tokens labeled as *Slogans* exhibits\nthe poorest results, despite being relatively easier\nto recognize for humans. This can be due to the\nlimited presence of examples/tokens in both the\ntraining and the test set [11] . In addition, these results\npoint out that recognizing slogans within political debates involves factors beyond syntactic and\nargumentative features (mostly semantics and pragmatics). On the contrary, tokens labeled as “Slippery Slope” and “False Cause” (with 332 and 321\nexamples, respectively) are much better classified\n\n10 A detailed analysis of the performances with BIO tokens\nis provided in Appendix B\n\n11 A detailed table with the count of each token can be found\nin Appendix C\n\n\nFigure 2: Normalized confusion matrix MultiFusion\nBERT. BIO labels are merged. Normalization is performed using the number of true elements in each class.\n\nby the model, showing the highest performances\n( 0 *.* 89 and 0 *.* 84 ). The definition of “Slippery Slope”\nrevolves around portraying improbable or exaggerated consequences arising from a specific action,\nand argumentative components are often used to\nthe cause, as well as semantic nuances well captured by the model.\n\nThe results obtained for the other labels are in\n\nline with those in (Goffredo et al., 2022) for the\nclassification task only. The addition of new fallacious examples from the 2020 debates kept unchanged the distribution of fallacies with respect to\nthe previous debates, suggesting that the detection\nof fallacious snippets remains consistent and stable\nacross different debate contexts.\n\nFor a better understanding of the predictions\nmade by the MultiFusion BERT we analyze the\nnormalized confusion matrix visualized in Figure 2.\nThe normalized version is preferred due to the\ndataset class imbalance. Notably, although the\nclass with the highest F1 score is *O* (representing\nnon-fallacies), the confusion matrix reveals that the\nmodel tends to over-predict instances in this category. As observed in the column of the predicted *O*\nclass, false positives are the most prevalent in the\nnon-fallacious tokens. Moreover, *False Cause* and\n*Appeal to Emotion* are the classes that the models\nmisinterpret the most as non fallacious. In a smaller\nproportion, the model misclassifies instances of *Ap-*\n*peal to Authority* as *Appeal to Emotion* .\nTable 6 shows a few misclassified fallacy snippets. In the first example, the argument is misclassified as Appeal to Emotion instead of Appel to\nAuthority, because the model is misled by the word\n\n\n11108\n\n\n-----\n\n**Fallacy snippet** **True** **Pred.**\n**fallac** **y** **fallac** **y**\n**Franklin Roosevelt said in 1932** A p peal to **Appeal** **to**\n**that the onl** **y** **thing we have to fear** Authority **Emotion**\n**is fear itself.**\n\n**As the President said the other** O **Appeal** **to**\n**night** **,** **there will always be trou-** **Authority**\n**bles in this ol’ world, but the** and *O*\n**United States of America** *can be*\n\n*counted on to provide the vision that*\n*the world looks for from the United*\n*States o* *f* *America.*\n\n**But as Admiral Yarnell has said,** A p peal to **Appeal** **to**\n**and he’s been su** **p** **ported by most** Authority **Emotion**\n**militar** **y** **authority, these islands** and *O*\n**that we’re now talkin** **g** **about are**\n**not worth the bones of a single**\n**American soldier** **;** *and I know how*\n*di* *ff* *icult it is to sustain troops close*\n*to the shore under artiller* *y* *bombard-*\n\n*ment.*\n\n**In a place like Chicago** **,** **where** False Cause **False**\n**thousands of people have been** **Cause** and\n**killed** **,** *thousands over the last* *O*\n*number o* *f* *years, in fact* *,* *almost*\n*4,000 have been killed since Barack*\n*Obama became president* *,* *overall al-*\n*most 4,000 people in Chicago have*\n*been killed. We have to brin* *g* *back*\n*law and order.*\n\nTable 6: Examples of misclassification using the bestperforming model. Underlined text is to highlight the\ntrue label for each token, whereas **Bold** is for the predicted fallacy and *Italic* for predicted *O* tokens.\n\n“fear,” which carries an important emotional connotation. In the next example, the argument is erroneously classified as being an Appeal to Authority\nargument whilst it is not a fallacious argument (O).\nThe third example shows another instance where\nthe model confuses Appeal to Authority with Appeal to Emotion, while also failing to identify part\nof the fallacy in general. The third and the fourth\nexamples show where the model partially identifies\nthe correct fallacy or its absence.\n## **6 Conclusion**\n\nExisting argumentation schemes (Walton, 1995) to\nidentify flawed and invalid forms of reasoning often fall short when applied to fallacious arguments\nemployed in real-world contexts like political debates. To tackle this challenge, the contribution\nof this paper is twofold. First, we extended the\nElecDeb60to16 dataset by incorporating the Trump\nvs. Biden 2020 presidential debate along with\nargumentative annotations and fallacies. Second,\nwe proposed and evaluated MultiFusion BERT, a\ntransformer-based architecture that combines the\n\ndebate text, the argumentative features (i.e., components and relations), and engineered features to\n\n\nperform the fallacy detection and classification task.\nOur results highlight the main role of argumentative\nfeatures in the correct identification and classification of fallacious arguments. This approach yields\nan average performance improvement of 2 *.* 12%\ncompared to baseline methods and competing approaches.\nAs future research, we intend to delve deeper\ninto fallacious argumentation by integrating knowledge in order to address more challenging fallacy\ncategories like causal ones, where reasoning and\nknowledge-based features are required to identify\nthe fallacy. Our further objective is to generate\nvalid arguments from identified fallacious ones and\ntheir context. Additionally, a challenge we aim\nto tackle is to explore ways to counter the formal\ninvalidity of fallacious arguments through the generation of new arguments.\n## **7 Limitations**\n\nSome limitations of this work require a discussion.\nFirstly, the used training corpus is focused on US\npolitical debates, which restricts the applicability of\nthe model to English-language contexts only. Furthermore, the imbalanced distribution of labels had\na noticeable impact on the model’s performance\nand its ability to generalize during prediction. For\ninstance, the label \"Slogan\" was significantly underrepresented compared to other labels, further affecting the model’s performance. Finally, it is important to consider that the GPU requirements, specifically the need for Nvidia RTX 8000 with 32GB\nVRAM, may present limitations on the practical\nutilization of these models in resource-constrained\n\nenvironments. These limitations highlight the need\nfor further research to address the dataset limita\ntions with respect to the employed language and\nthe label balance, to improve the model architecture, and explore additional strategies to enhance\nfallacy detection through knowledge injection. **8 Acknowledgments**\n\nThis work was partly supported by the French government, through the 3IA Côte d’Azur Investments\nin the Future project managed by the National Research Agency (ANR) with the reference number\nANR-19-P3IA-0002. This work was partly supported also by EU Horizon 2020 project AI4Media,\nunder contract no. 951911 (https://ai4media.eu/).\nThis work has been partially supported by the ANR\nproject ATTENTION (ANR-21-CE23-0037).\n\n\n11109\n\n\n-----\n\n## **References**\n\nTariq Alhindi, Tuhin Chakrabarty, Elena Musi, and\nSmaranda Muresan. 2022. [Multitask instruction-](https://doi.org/10.18653/v1/2022.emnlp-main.560)\n[based prompting for fallacy recognition. In](https://doi.org/10.18653/v1/2022.emnlp-main.560) *Proceed-*\n*ings of the 2022 Conference on Empirical Methods*\n*in Natural Language Processing*, pages 8172–8187,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\n\n[Elena Cabrio and Serena Villata. 2018. Five years of](https://doi.org/10.24963/ijcai.2018/766)\n[argument mining: a data-driven analysis. In](https://doi.org/10.24963/ijcai.2018/766) *Proceed-*\n*ings of the Twenty-Seventh International Joint Con-*\n*ference on Artificial Intelligence, IJCAI 2018, July*\n*13-19, 2018, Stockholm, Sweden*, pages 5427–5433.\nijcai.org.\n\nGiovanni Da San Martino, Alberto Barrón-Cedeño, and\n[Preslav Nakov. 2019a. Findings of the NLP4IF-2019](https://doi.org/10.18653/v1/D19-5024)\n[shared task on fine-grained propaganda detection. In](https://doi.org/10.18653/v1/D19-5024)\n*Proceedings of the Second Workshop on Natural Lan-*\n*guage Processing for Internet Freedom: Censorship,*\n*Disinformation, and Propaganda*, pages 162–170,\nHong Kong, China. Association for Computational\nLinguistics.\n\nGiovanni Da San Martino, Alberto Barrón-Cedeño,\nHenning Wachsmuth, Rostislav Petrov, and Preslav\n[Nakov. 2020a. SemEval-2020 task 11: Detection](https://doi.org/10.18653/v1/2020.semeval-1.186)\n[of propaganda techniques in news articles. In](https://doi.org/10.18653/v1/2020.semeval-1.186) *Pro-*\n*ceedings of the Fourteenth Workshop on Semantic*\n*Evaluation*, pages 1377–1414, Barcelona (online).\nInternational Committee for Computational Linguistics.\n\nGiovanni Da San Martino, Stefano Cresci, Alberto\nBarrón-Cedeño, Seunghak Yu, Roberto Di Pietro,\n[and Preslav Nakov. 2020b. A survey on computa-](https://doi.org/10.24963/ijcai.2020/672)\n[tional propaganda detection. In](https://doi.org/10.24963/ijcai.2020/672) *Proceedings of the*\n*Twenty-Ninth International Joint Conference on Arti-*\n*ficial Intelligence, IJCAI-20*, pages 4826–4832. International Joint Conferences on Artificial Intelligence\nOrganization. Survey track.\n\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarrón-Cedeno, Rostislav Petrov, and Preslav Nakov.\n2019b. Fine-grained analysis of propaganda in news\narticle. In *Proceedings of the 2019 conference on*\n*empirical methods in natural language processing*\n*and the 9th international joint conference on natu-*\n*ral language processing (EMNLP-IJCNLP)*, pages\n5636–5646.\n\nFrans H. Van Eemeren. 2001. Fallacies. *Critical con-*\n*cepts in argumentation theory*, page 135–164.\n\nFrans H. Van Eemeren and Rob Grootendorst. 1987.\n\n[Fallacies in pragma-dialectical perspective.](https://doi.org/10.1007/bf00136779) *Argu-*\n*mentation*, 1(3):283–301.\n\nPierpaolo Goffredo, Shohreh Haddadan, Vorakit Vorak[itphan, Elena Cabrio, and Serena Villata. 2022. Fal-](https://doi.org/10.24963/ijcai.2022/575)\n[lacious argument classification in political debates.](https://doi.org/10.24963/ijcai.2022/575)\nIn *Proceedings of the Thirty-First International*\n*Joint Conference on Artificial Intelligence, IJCAI-22*,\n\n\npages 4143–4149. International Joint Conferences on\nArtificial Intelligence Organization. Main Track.\n\nIvan Habernal, Raffael Hannemann, Christian Pollak, Christopher Klamm, Patrick Pauli, and Iryna\n[Gurevych. 2017. Argotario: Computational argu-](https://doi.org/10.18653/v1/D17-2002)\n[mentation meets serious games. In](https://doi.org/10.18653/v1/D17-2002) *Proceedings of*\n*the 2017 Conference on Empirical Methods in Nat-*\n*ural Language Processing: System Demonstrations*,\npages 7–12, Copenhagen, Denmark. Association for\nComputational Linguistics.\n\nIvan Habernal, Patrick Pauli, and Iryna Gurevych. 2018.\n\n[Adapting Serious Game for Fallacious Argumenta-](https://aclanthology.org/L18-1526)\n[tion to German: Pitfalls, Insights, and Best Prac-](https://aclanthology.org/L18-1526)\n[tices. In](https://aclanthology.org/L18-1526) *Proceedings of the Eleventh International*\n*Conference on Language Resources and Evaluation*\n*(LREC 2018)*, Miyazaki, Japan. European Language\nResources Association (ELRA).\n\nShohreh Haddadan, Elena Cabrio, and Serena Villata.\n[2019. Yes, we can! mining arguments in 50 years of](https://doi.org/10.18653/v1/P19-1463)\n[US presidential campaign debates. In](https://doi.org/10.18653/v1/P19-1463) *Proceedings of*\n*the 57th Annual Meeting of the Association for Com-*\n*putational Linguistics*, pages 4684–4690, Florence,\nItaly. Association for Computational Linguistics.\n\nZhijing Jin, Abhinav Lalwani, Tejas Vaidhya, Xiaoyu Shen, Yiwen Ding, Zhiheng Lyu, Mrinmaya\nSachan, Rada Mihalcea, and Bernhard Schölkopf.\n2022. Logical fallacy detection. *arXiv preprint*\n*arXiv:2202.13758* .\n\nJan-Christoph Klie, Michael Bugert, Beto Boullosa,\nRichard Eckart de Castilho, and Iryna Gurevych.\n[2018. The INCEpTION platform: Machine-assisted](https://aclanthology.org/C18-2002)\n[and knowledge-oriented interactive annotation. In](https://aclanthology.org/C18-2002)\n*Proceedings of the 27th International Conference on*\n*Computational Linguistics: System Demonstrations*,\npages 5–9, Santa Fe, New Mexico. Association for\nComputational Linguistics.\n\nAnne Lauscher, Henning Wachsmuth, Iryna Gurevych,\n[and Goran Glavas. 2022. Scientia potentia est - on the](https://transacl.org/ojs/index.php/tacl/article/view/3967)\n[role of knowledge in computational argumentation.](https://transacl.org/ojs/index.php/tacl/article/view/3967)\n*Trans. Assoc. Comput. Linguistics*, 10:1392–1422.\n\n[John Lawrence and Chris Reed. 2019. Argument min-](https://doi.org/10.1162/coli_a_00364)\n[ing: A survey.](https://doi.org/10.1162/coli_a_00364) *Comput. Linguistics*, 45(4):765–818.\n\nElena Musi, Myrto Aloumpi, Elinor Carmi, Simeon\nYates, and Kay O’Halloran. 2022. Developing fake\nnews immunity: fallacies as misinformation triggers\nduring the pandemic. *Online Journal of Communica-*\n*tion and Media Technologies*, 12(3).\n\nSaumya Sahai, Oana Balalau, and Roxana Horincar.\n[2021. Breaking down the invisible wall of infor-](https://doi.org/10.18653/v1/2021.acl-long.53)\n[mal fallacies in online discussions. In](https://doi.org/10.18653/v1/2021.acl-long.53) *Proceedings*\n*of the 59th Annual Meeting of the Association for*\n*Computational Linguistics and the 11th International*\n*Joint Conference on Natural Language Processing*\n*(Volume 1: Long Papers)*, pages 644–657, Online.\nAssociation for Computational Linguistics.\n\n\n11110\n\n\n-----\n\nPrashanth Vijayaraghavan and Soroush Vosoughi. 2022.\n\n[TWEETSPIN: Fine-grained propaganda detection in](https://doi.org/10.18653/v1/2022.naacl-main.251)\n[social media using multi-view representations. In](https://doi.org/10.18653/v1/2022.naacl-main.251)\n*Proceedings of the 2022 Conference of the North*\n*American Chapter of the Association for Computa-*\n*tional Linguistics: Human Language Technologies*,\npages 3433–3448, Seattle, United States. Association\nfor Computational Linguistics.\n\nVorakit Vorakitphan, Elena Cabrio, and Serena Villata.\n[2021. ”Don’t discuss”: Investigating Semantic and](https://hal.science/hal-03314797)\n[Argumentative Features for Supervised Propagandist](https://hal.science/hal-03314797)\n[Message Detection and Classification. In](https://hal.science/hal-03314797) *RANLP*\n*2021 - Recent Advances in Natural Language Pro-*\n*cessing*, Varna / Virtual, Bulgaria.\n\nVorakit Vorakitphan, Elena Cabrio, and Serena Villata.\n2022. Protect: A pipeline for propaganda detection\nand classification. In *CLiC-it 2021-Italian Confer-*\n*ence on Computational Linguistics* .\n\nD.N. Walton. 1987. *[Informal Fallacies: Towards a The-](https://books.google.fr/books?id=9vbWAAAAMAAJ)*\n*[ory of Argument Criticisms](https://books.google.fr/books?id=9vbWAAAAMAAJ)* . Pragmatics & beyond\ncompanion series. J. Benjamins Publishing Company.\n\nD.N. Walton. 1995. *[A Pragmatic Theory of Fallacy](https://books.google.fr/books?id=4uTWAAAAMAAJ)* .\nStudies in rhetoric and communication. University of\nAlabama Press.\n## **A Encoding**\n\nA representation of the dataset’s encoded example Figure 3: Encoded example of a single item of the\n\ndataset ElecDeb60to20.\n\nis illustrated in the Figure 3, demonstrating how it\nis prepared for input into the architecture for token **Label** **p** **recision** **recall** **f1-score** **su** **pp** **ort**\nlabel prediction. Notably, the argument features B-AdHominem 1.00 0.19 0.31 27\nalign with the offset mapping approach employed B-AppealtoAuthority 0.75 0.50 0.60 30\n\nB-AppealtoEmotion 0.72 0.39 0.51 120\n\nby the tokenizer during tokenization. B-FalseCause 0.75 0.33 0.46 9\nEach argumentative feature is represented by a B-Slipperyslope 0.33 0.12 0.18 8\ntensor of length 256 (the maximum token length B-Slogans 0.00 0.00 0.00 5\n\nI-AdHominem 0.98 0.79 0.88 712\n\nof 216 is used) filled with label IDs ( 0 : *None*, 1 : I-AppealtoAuthority 0.90 0.78 0.84 1’019\n*Claim/Support*, 2 : *Premise/Attack* ) up to the max- I-AppealtoEmotion 0.81 0.78 0.79 2’104\nimum length. The same process is applied to the I-FalseCause 0.81 0.87 0.84 312\n\nI-Slipperyslope 0.89 0.89 0.89 324\n\nPart-of-Speech tensor, where each tag is converted I-Slogans 0.00 0.00 0.00 44\ninto its corresponding ID ( 0 : *ADJ*, 1 : *ADP*, 2 : *ADV*, O 0.90 0.95 0.93 7’914\n3 : *AUX*, 4 : *CCONJ*, 5 : *DET*, 6 : *INTJ*, 7 : *NOUN*, accuracymacro avg 0.68 0.51 0.88 **0.56** 12’62812’628\n8 : *NUM*, 9 : *PART*, 10 : *PRON*, 11 : *PROPN*, 12 : wei g hted av g 0.88 0.88 0.88 12’628\n*PUNCT*, 13: *SCONJ*, 14: *SYM*, 15: *VERB*, 16: *X* ).\n\nTable 7: Classification report of fallacy entity classifica- B Detailed Model Performance tion with BIO labels.\n\nIn this appendix section, a comprehensive classifi- cation report of the best-performing model is pre- C Token Distribution\n\nsented, considering all BIO labels and all the three\n\nTable 8 shows the distribution of the BIO tokens\n\nfeatures (argumentative components, argumenta\namong the training and test set.\n\ntive relations and PoS tags). This report provides a thorough assessment of the model performance, D Analysis of Different α Values\n\noffering valuable insights into its accuracy and effectiveness in recognizing and classifying different MultiFusion BERT’s loss function is defined as\ncategories to every token. *joint* *loss* = *α ∗* [(] *[loss]* *[f]* *[al]* [+] *[loss]* *[cm]* *N* *[p]* *loss* [+] *[loss]* *[rel]* [+] *[loss]* *[P oS]* [)],\n\n11111\n\n\n-----\n\n|Label Train Test|Total|\n|---|---|\n|B-AdHominem 243 27 B-AppealtoAuthority 272 30 B-AppealtoEmotion 1’073 120 B-FalseCause 84 9 B-Slipperyslope 71 8 B-Slogans 47 5 I-AdHominem 4’855 712 I-AppealtoAuthority 8’707 1’019 I-AppealtoEmotion 17’408 2’104 I-FalseCause 3’076 312 I-Slipperyslope 2’487 324 I-Slogans 254 44 O 74’493 7’914|270 302 1’193 93 79 52 5’567 9’726 19’512 3’388 2’811 298 82407|\n|Total 113’070 12’628|125’698|\n\n\nTable 8: Distribution of BIO fallacy tags among the\ntrain and test set.\n\n**Features** **Avg macro**\n*α*\n**Com** **p** **onents** **Relationshi** **p** **s** **PoS** **F1 Score**\n\n✓ 0.6922\n\n✓ 0.6922\n\n✓ 0.7212\n\n0.1 ✓ ✓ 0.7278\n\n✓ ✓ 0.7166\n\n✓ ✓ 0.7166\n\n✓ ✓ ✓ **0.7394**\n\n✓ 0.7054\n\n✓ 0.7054\n\n✓ **0.7214**\n\n0.3 ✓ ✓ 0.6889\n\n✓ ✓ 0.7160\n\n✓ ✓ 0.7160\n\n✓ ✓ ✓ 0.7084\n\n✓ 0.7057\n\n✓ 0.7057\n\n✓ 0.6817\n\n0.5 ✓ ✓ **0.7366**\n\n✓ ✓ 0.7054\n\n✓ ✓ 0.7054\n\n✓ ✓ ✓ 0.7070\n\nTable 9: MultiFusion BERT’s average macro F1 scores\nfor fallacy detection using different features and values\nof the *α* parameter. The scores are based on an average\nof 3 runs. *B* and *I* labels were merged.\n\nwhere *N* *loss* denotes the number of losses considered by the model. We conducted an exploration of\nvarious values for the *α* parameter. Table 9 shows\nthat the impact of the parameter varies depending\non the features used in the model. That is, none of\nthe values of *α* yields a generalized improvement in\nthe macro F1 score across all feature combinations.\n\n11112\n\n\n-----"
      },
      {
        "role": "assistant",
        "content": "Fallacies are arguments that employ faulty reasoning. Given their persuasive and seemingly\nvalid nature, fallacious arguments are often\nused in political debates. Employing these misleading arguments in politics can have detrimental consequences for society, since they\ncan lead to inaccurate conclusions and invalid\n\ninferences from the public opinion and the policymakers. Automatically detecting and classifying fallacious arguments represents therefore\na crucial challenge to limit the spread of misleading or manipulative claims and promote\na more informed and healthier political discourse. Our contribution to address this chal\nlenging task is twofold. First, we extend the\nElecDeb60To16 dataset of U.S. presidential\ndebates annotated with fallacious arguments,\nby incorporating the most recent Trump-Biden\npresidential debate. We include updated tokenlevel annotations, incorporating argumentative\ncomponents (i.e., claims and premises), the relations between these components (i.e., support\nand attack), and six categories of fallacious arguments (i.e., Ad Hominem, Appeal to Authority, Appeal to Emotion, False Cause, Slippery\nSlope, and Slogans). Second, we perform the\ntwofold task of fallacious argument detection\nand classification by defining neural network\narchitectures based on Transformers models,\ncombining text, argumentative features, and engineered features. Our results show the advantages of complementing transformer-generated\ntext representations with non-textual features."
      }
    ]
  }
]